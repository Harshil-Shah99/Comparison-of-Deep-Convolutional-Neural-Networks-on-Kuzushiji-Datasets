{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet121_K49.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGtnn8_5Jpcx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "f2b8dd23-b4e5-433f-d904-6de7bfa89574"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import svm, metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "from skimage.transform import resize, rescale\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import data, color\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from numpy import savez_compressed\n",
        "from google.colab import files\n",
        "from numpy import load\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.callbacks import EarlyStopping\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "filename = '/content/gdrive/My Drive/Research2/np_data/x.npz'\n",
        "x = np.load(filename)['arr_0']\n",
        "\n",
        "filename = '/content/gdrive/My Drive/Research2/np_data/y.npz'\n",
        "y = np.load(filename)['arr_0']\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "(270912, 56, 56, 1)\n",
            "(270912, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnmg_DwMJ2GH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d481ae90-791d-4ebc-d409-be005cce82f5"
      },
      "source": [
        "baseAccuracies = []\n",
        "losses = []\n",
        "balancedAccuracies = []\n",
        "f1scores = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "fold_no = 1\n",
        "callback = EarlyStopping(monitor = 'val_loss', patience = 2, verbose = 1)\n",
        "\n",
        "for train, test in kfold.split(x, y):\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  print(\"Fold number: \" + str(fold_no))\n",
        "  fold_no = fold_no+1\n",
        "  print()\n",
        "\n",
        "  xtrain = x[train]\n",
        "  xtest = x[test]\n",
        "  \n",
        "  model = tf.keras.applications.DenseNet121(include_top=True, weights=None, input_shape=(56, 56, 1), classes=49,)\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=Adam(lr=0.0001), metrics=[\"sparse_categorical_accuracy\"])\n",
        "  model.fit(xtrain, y[train], verbose = 1, validation_data = (xtest, y[test]), epochs = 10, callbacks = [callback], batch_size = 32)\n",
        "\n",
        "  test_loss, test_accuracy = model.evaluate(xtest, y[test])\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  print(\"Test Accuracy:\")\n",
        "  print(test_accuracy)\n",
        "  baseAccuracies.append(test_accuracy)\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  print(\"Test Loss:\")\n",
        "  print(test_loss)\n",
        "  losses.append(test_loss)\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  preds = np.argmax(model.predict(xtest), axis=-1)\n",
        "  preds = preds.reshape(len(xtest), 1)\n",
        "  accs = []\n",
        "  for cls in range(49):\n",
        "    mask = (y[test] == cls)\n",
        "    cls_acc = (preds == cls)[mask].mean() \n",
        "    accs.append(cls_acc)\n",
        "  accs = np.mean(accs)\n",
        "  print(\"Final balanced accuracy:\")\n",
        "  print(accs)\n",
        "  balancedAccuracies.append(accs)\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  f1scores.append(f1_score(y[test], preds, average = 'weighted'))\n",
        "  precisions.append(precision_score(y[test], preds, average = 'weighted'))\n",
        "  recalls.append(recall_score(y[test], preds, average = 'weighted'))\n",
        "  print(\"*********************************************************************************************************************************\")\n",
        "  print()\n",
        "  print()\n",
        "  del model, xtrain, xtest"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 1\n",
            "\n",
            "Epoch 1/10\n",
            "7620/7620 [==============================] - 293s 38ms/step - loss: 0.4506 - sparse_categorical_accuracy: 0.8822 - val_loss: 0.1914 - val_sparse_categorical_accuracy: 0.9456\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 291s 38ms/step - loss: 0.1430 - sparse_categorical_accuracy: 0.9593 - val_loss: 0.1455 - val_sparse_categorical_accuracy: 0.9578\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 291s 38ms/step - loss: 0.0997 - sparse_categorical_accuracy: 0.9712 - val_loss: 0.1115 - val_sparse_categorical_accuracy: 0.9683\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 290s 38ms/step - loss: 0.0760 - sparse_categorical_accuracy: 0.9777 - val_loss: 0.0981 - val_sparse_categorical_accuracy: 0.9722\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 291s 38ms/step - loss: 0.0614 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0948 - val_sparse_categorical_accuracy: 0.9732\n",
            "Epoch 6/10\n",
            "7620/7620 [==============================] - 289s 38ms/step - loss: 0.0505 - sparse_categorical_accuracy: 0.9846 - val_loss: 0.0955 - val_sparse_categorical_accuracy: 0.9746\n",
            "Epoch 7/10\n",
            "7620/7620 [==============================] - 287s 38ms/step - loss: 0.0434 - sparse_categorical_accuracy: 0.9867 - val_loss: 0.0952 - val_sparse_categorical_accuracy: 0.9752\n",
            "Epoch 00007: early stopping\n",
            "847/847 [==============================] - 11s 13ms/step - loss: 0.0952 - sparse_categorical_accuracy: 0.9752\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9752325415611267\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.09524818509817123\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9736809674136414\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 2\n",
            "\n",
            "Epoch 1/10\n",
            "7620/7620 [==============================] - 290s 38ms/step - loss: 0.4293 - sparse_categorical_accuracy: 0.8881 - val_loss: 0.1852 - val_sparse_categorical_accuracy: 0.9485\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 287s 38ms/step - loss: 0.1395 - sparse_categorical_accuracy: 0.9602 - val_loss: 0.1494 - val_sparse_categorical_accuracy: 0.9601\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 288s 38ms/step - loss: 0.0981 - sparse_categorical_accuracy: 0.9717 - val_loss: 0.1315 - val_sparse_categorical_accuracy: 0.9630\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 287s 38ms/step - loss: 0.0756 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.1179 - val_sparse_categorical_accuracy: 0.9674\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 287s 38ms/step - loss: 0.0602 - sparse_categorical_accuracy: 0.9820 - val_loss: 0.0935 - val_sparse_categorical_accuracy: 0.9757\n",
            "Epoch 6/10\n",
            "7620/7620 [==============================] - 288s 38ms/step - loss: 0.0496 - sparse_categorical_accuracy: 0.9846 - val_loss: 0.0952 - val_sparse_categorical_accuracy: 0.9759\n",
            "Epoch 7/10\n",
            "7620/7620 [==============================] - 288s 38ms/step - loss: 0.0417 - sparse_categorical_accuracy: 0.9869 - val_loss: 0.0915 - val_sparse_categorical_accuracy: 0.9782\n",
            "Epoch 8/10\n",
            "7620/7620 [==============================] - 288s 38ms/step - loss: 0.0370 - sparse_categorical_accuracy: 0.9881 - val_loss: 0.0842 - val_sparse_categorical_accuracy: 0.9800\n",
            "Epoch 9/10\n",
            "7620/7620 [==============================] - 288s 38ms/step - loss: 0.0328 - sparse_categorical_accuracy: 0.9894 - val_loss: 0.0879 - val_sparse_categorical_accuracy: 0.9801\n",
            "Epoch 10/10\n",
            "7620/7620 [==============================] - 288s 38ms/step - loss: 0.0280 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.0939 - val_sparse_categorical_accuracy: 0.9784\n",
            "Epoch 00010: early stopping\n",
            "847/847 [==============================] - 11s 13ms/step - loss: 0.0939 - sparse_categorical_accuracy: 0.9784\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9784069061279297\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.0938861295580864\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9756921460402637\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 3\n",
            "\n",
            "Epoch 1/10\n",
            "7620/7620 [==============================] - 292s 38ms/step - loss: 0.4393 - sparse_categorical_accuracy: 0.8838 - val_loss: 0.1860 - val_sparse_categorical_accuracy: 0.9466\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 290s 38ms/step - loss: 0.1403 - sparse_categorical_accuracy: 0.9608 - val_loss: 0.1462 - val_sparse_categorical_accuracy: 0.9576\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 290s 38ms/step - loss: 0.0980 - sparse_categorical_accuracy: 0.9718 - val_loss: 0.1133 - val_sparse_categorical_accuracy: 0.9682\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 291s 38ms/step - loss: 0.0748 - sparse_categorical_accuracy: 0.9780 - val_loss: 0.0993 - val_sparse_categorical_accuracy: 0.9731\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 293s 38ms/step - loss: 0.0617 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1043 - val_sparse_categorical_accuracy: 0.9713\n",
            "Epoch 6/10\n",
            "7620/7620 [==============================] - 291s 38ms/step - loss: 0.0500 - sparse_categorical_accuracy: 0.9846 - val_loss: 0.0868 - val_sparse_categorical_accuracy: 0.9763\n",
            "Epoch 7/10\n",
            "7620/7620 [==============================] - 290s 38ms/step - loss: 0.0422 - sparse_categorical_accuracy: 0.9869 - val_loss: 0.0922 - val_sparse_categorical_accuracy: 0.9757\n",
            "Epoch 8/10\n",
            "7620/7620 [==============================] - 290s 38ms/step - loss: 0.0360 - sparse_categorical_accuracy: 0.9884 - val_loss: 0.0845 - val_sparse_categorical_accuracy: 0.9787\n",
            "Epoch 9/10\n",
            "7620/7620 [==============================] - 290s 38ms/step - loss: 0.0322 - sparse_categorical_accuracy: 0.9897 - val_loss: 0.0961 - val_sparse_categorical_accuracy: 0.9764\n",
            "Epoch 10/10\n",
            "7620/7620 [==============================] - 290s 38ms/step - loss: 0.0287 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.1035 - val_sparse_categorical_accuracy: 0.9729\n",
            "Epoch 00010: early stopping\n",
            "847/847 [==============================] - 11s 13ms/step - loss: 0.1035 - sparse_categorical_accuracy: 0.9729\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9729430675506592\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.10349077731370926\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9730794832785572\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 4\n",
            "\n",
            "Epoch 1/10\n",
            "7620/7620 [==============================] - 292s 38ms/step - loss: 0.4344 - sparse_categorical_accuracy: 0.8863 - val_loss: 0.2033 - val_sparse_categorical_accuracy: 0.9402\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 291s 38ms/step - loss: 0.1401 - sparse_categorical_accuracy: 0.9602 - val_loss: 0.1245 - val_sparse_categorical_accuracy: 0.9651\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 291s 38ms/step - loss: 0.0968 - sparse_categorical_accuracy: 0.9721 - val_loss: 0.1148 - val_sparse_categorical_accuracy: 0.9673\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 290s 38ms/step - loss: 0.0753 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.0964 - val_sparse_categorical_accuracy: 0.9724\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 290s 38ms/step - loss: 0.0605 - sparse_categorical_accuracy: 0.9821 - val_loss: 0.0986 - val_sparse_categorical_accuracy: 0.9720\n",
            "Epoch 6/10\n",
            "7620/7620 [==============================] - 290s 38ms/step - loss: 0.0492 - sparse_categorical_accuracy: 0.9850 - val_loss: 0.0895 - val_sparse_categorical_accuracy: 0.9756\n",
            "Epoch 7/10\n",
            "7620/7620 [==============================] - 290s 38ms/step - loss: 0.0431 - sparse_categorical_accuracy: 0.9866 - val_loss: 0.1023 - val_sparse_categorical_accuracy: 0.9725\n",
            "Epoch 8/10\n",
            "7620/7620 [==============================] - 293s 38ms/step - loss: 0.0368 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0873 - val_sparse_categorical_accuracy: 0.9768\n",
            "Epoch 9/10\n",
            "7620/7620 [==============================] - 291s 38ms/step - loss: 0.0320 - sparse_categorical_accuracy: 0.9897 - val_loss: 0.0897 - val_sparse_categorical_accuracy: 0.9770\n",
            "Epoch 10/10\n",
            "7620/7620 [==============================] - 291s 38ms/step - loss: 0.0291 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.0889 - val_sparse_categorical_accuracy: 0.9776\n",
            "Epoch 00010: early stopping\n",
            "847/847 [==============================] - 11s 13ms/step - loss: 0.0889 - sparse_categorical_accuracy: 0.9776\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9776309728622437\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.08889444172382355\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9755495507931318\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 5\n",
            "\n",
            "Epoch 1/10\n",
            "7620/7620 [==============================] - 292s 38ms/step - loss: 0.4404 - sparse_categorical_accuracy: 0.8847 - val_loss: 0.2120 - val_sparse_categorical_accuracy: 0.9403\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 292s 38ms/step - loss: 0.1418 - sparse_categorical_accuracy: 0.9598 - val_loss: 0.1187 - val_sparse_categorical_accuracy: 0.9680\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 293s 38ms/step - loss: 0.0983 - sparse_categorical_accuracy: 0.9717 - val_loss: 0.1150 - val_sparse_categorical_accuracy: 0.9685\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 294s 39ms/step - loss: 0.0753 - sparse_categorical_accuracy: 0.9777 - val_loss: 0.0990 - val_sparse_categorical_accuracy: 0.9726\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 296s 39ms/step - loss: 0.0603 - sparse_categorical_accuracy: 0.9820 - val_loss: 0.0890 - val_sparse_categorical_accuracy: 0.9762\n",
            "Epoch 6/10\n",
            "7620/7620 [==============================] - 298s 39ms/step - loss: 0.0502 - sparse_categorical_accuracy: 0.9849 - val_loss: 0.0971 - val_sparse_categorical_accuracy: 0.9748\n",
            "Epoch 7/10\n",
            "7620/7620 [==============================] - 297s 39ms/step - loss: 0.0424 - sparse_categorical_accuracy: 0.9868 - val_loss: 0.0910 - val_sparse_categorical_accuracy: 0.9770\n",
            "Epoch 00007: early stopping\n",
            "847/847 [==============================] - 11s 13ms/step - loss: 0.0910 - sparse_categorical_accuracy: 0.9770\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9770034551620483\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.09104037284851074\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9722403485002241\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 6\n",
            "\n",
            "Epoch 1/10\n",
            "7620/7620 [==============================] - 299s 39ms/step - loss: 0.4437 - sparse_categorical_accuracy: 0.8842 - val_loss: 0.1811 - val_sparse_categorical_accuracy: 0.9467\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 296s 39ms/step - loss: 0.1420 - sparse_categorical_accuracy: 0.9600 - val_loss: 0.1331 - val_sparse_categorical_accuracy: 0.9621\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 296s 39ms/step - loss: 0.0988 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1087 - val_sparse_categorical_accuracy: 0.9674\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 295s 39ms/step - loss: 0.0750 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.1046 - val_sparse_categorical_accuracy: 0.9706\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 294s 39ms/step - loss: 0.0600 - sparse_categorical_accuracy: 0.9820 - val_loss: 0.0894 - val_sparse_categorical_accuracy: 0.9738\n",
            "Epoch 6/10\n",
            "7620/7620 [==============================] - 294s 39ms/step - loss: 0.0507 - sparse_categorical_accuracy: 0.9845 - val_loss: 0.0834 - val_sparse_categorical_accuracy: 0.9767\n",
            "Epoch 7/10\n",
            "7620/7620 [==============================] - 293s 38ms/step - loss: 0.0427 - sparse_categorical_accuracy: 0.9869 - val_loss: 0.0841 - val_sparse_categorical_accuracy: 0.9773\n",
            "Epoch 8/10\n",
            "7620/7620 [==============================] - 293s 39ms/step - loss: 0.0366 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.0879 - val_sparse_categorical_accuracy: 0.9761\n",
            "Epoch 00008: early stopping\n",
            "847/847 [==============================] - 11s 13ms/step - loss: 0.0879 - sparse_categorical_accuracy: 0.9761\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9761175513267517\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.08785446733236313\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9730252884686298\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 7\n",
            "\n",
            "Epoch 1/10\n",
            "7620/7620 [==============================] - 298s 39ms/step - loss: 0.4343 - sparse_categorical_accuracy: 0.8864 - val_loss: 0.1565 - val_sparse_categorical_accuracy: 0.9560\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 297s 39ms/step - loss: 0.1402 - sparse_categorical_accuracy: 0.9601 - val_loss: 0.1309 - val_sparse_categorical_accuracy: 0.9628\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 298s 39ms/step - loss: 0.0981 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.1111 - val_sparse_categorical_accuracy: 0.9682\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 300s 39ms/step - loss: 0.0757 - sparse_categorical_accuracy: 0.9779 - val_loss: 0.0984 - val_sparse_categorical_accuracy: 0.9727\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 299s 39ms/step - loss: 0.0602 - sparse_categorical_accuracy: 0.9822 - val_loss: 0.0955 - val_sparse_categorical_accuracy: 0.9745\n",
            "Epoch 6/10\n",
            "7620/7620 [==============================] - 294s 39ms/step - loss: 0.0494 - sparse_categorical_accuracy: 0.9849 - val_loss: 0.0955 - val_sparse_categorical_accuracy: 0.9743\n",
            "Epoch 7/10\n",
            "7620/7620 [==============================] - 300s 39ms/step - loss: 0.0421 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.0968 - val_sparse_categorical_accuracy: 0.9760\n",
            "Epoch 00007: early stopping\n",
            "847/847 [==============================] - 11s 13ms/step - loss: 0.0968 - sparse_categorical_accuracy: 0.9760\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.976006805896759\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.09682947397232056\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9748201624647035\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 8\n",
            "\n",
            "Epoch 1/10\n",
            "7620/7620 [==============================] - 298s 39ms/step - loss: 0.4477 - sparse_categorical_accuracy: 0.8817 - val_loss: 0.1881 - val_sparse_categorical_accuracy: 0.9475\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 296s 39ms/step - loss: 0.1419 - sparse_categorical_accuracy: 0.9599 - val_loss: 0.1263 - val_sparse_categorical_accuracy: 0.9655\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 296s 39ms/step - loss: 0.0988 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.0952 - val_sparse_categorical_accuracy: 0.9736\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 296s 39ms/step - loss: 0.0761 - sparse_categorical_accuracy: 0.9779 - val_loss: 0.1013 - val_sparse_categorical_accuracy: 0.9730\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 296s 39ms/step - loss: 0.0602 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0907 - val_sparse_categorical_accuracy: 0.9756\n",
            "Epoch 6/10\n",
            "7620/7620 [==============================] - 295s 39ms/step - loss: 0.0507 - sparse_categorical_accuracy: 0.9846 - val_loss: 0.0980 - val_sparse_categorical_accuracy: 0.9738\n",
            "Epoch 7/10\n",
            "7620/7620 [==============================] - 296s 39ms/step - loss: 0.0421 - sparse_categorical_accuracy: 0.9869 - val_loss: 0.0869 - val_sparse_categorical_accuracy: 0.9781\n",
            "Epoch 8/10\n",
            "7620/7620 [==============================] - 296s 39ms/step - loss: 0.0370 - sparse_categorical_accuracy: 0.9883 - val_loss: 0.0933 - val_sparse_categorical_accuracy: 0.9771\n",
            "Epoch 9/10\n",
            "7620/7620 [==============================] - 297s 39ms/step - loss: 0.0328 - sparse_categorical_accuracy: 0.9897 - val_loss: 0.0866 - val_sparse_categorical_accuracy: 0.9790\n",
            "Epoch 10/10\n",
            "7620/7620 [==============================] - 297s 39ms/step - loss: 0.0282 - sparse_categorical_accuracy: 0.9911 - val_loss: 0.0918 - val_sparse_categorical_accuracy: 0.9781\n",
            "847/847 [==============================] - 11s 13ms/step - loss: 0.0918 - sparse_categorical_accuracy: 0.9781\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9781477451324463\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.09183358401060104\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9750273558961515\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 9\n",
            "\n",
            "Epoch 1/10\n",
            "7620/7620 [==============================] - 302s 40ms/step - loss: 0.4369 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.1737 - val_sparse_categorical_accuracy: 0.9511\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 293s 38ms/step - loss: 0.1437 - sparse_categorical_accuracy: 0.9595 - val_loss: 0.1201 - val_sparse_categorical_accuracy: 0.9660\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 299s 39ms/step - loss: 0.0988 - sparse_categorical_accuracy: 0.9718 - val_loss: 0.1101 - val_sparse_categorical_accuracy: 0.9680\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 301s 39ms/step - loss: 0.0757 - sparse_categorical_accuracy: 0.9777 - val_loss: 0.0910 - val_sparse_categorical_accuracy: 0.9756\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 300s 39ms/step - loss: 0.0615 - sparse_categorical_accuracy: 0.9817 - val_loss: 0.0944 - val_sparse_categorical_accuracy: 0.9758\n",
            "Epoch 6/10\n",
            "7620/7620 [==============================] - 300s 39ms/step - loss: 0.0502 - sparse_categorical_accuracy: 0.9846 - val_loss: 0.0933 - val_sparse_categorical_accuracy: 0.9753\n",
            "Epoch 00006: early stopping\n",
            "847/847 [==============================] - 11s 13ms/step - loss: 0.0933 - sparse_categorical_accuracy: 0.9753\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9753423929214478\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.09331969916820526\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9733239991184561\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 10\n",
            "\n",
            "Epoch 1/10\n",
            "7620/7620 [==============================] - 302s 40ms/step - loss: 0.4312 - sparse_categorical_accuracy: 0.8871 - val_loss: 0.1863 - val_sparse_categorical_accuracy: 0.9478\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 302s 40ms/step - loss: 0.1408 - sparse_categorical_accuracy: 0.9600 - val_loss: 0.1284 - val_sparse_categorical_accuracy: 0.9635\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 301s 39ms/step - loss: 0.0979 - sparse_categorical_accuracy: 0.9721 - val_loss: 0.1046 - val_sparse_categorical_accuracy: 0.9715\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 301s 39ms/step - loss: 0.0752 - sparse_categorical_accuracy: 0.9780 - val_loss: 0.1010 - val_sparse_categorical_accuracy: 0.9731\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 301s 39ms/step - loss: 0.0600 - sparse_categorical_accuracy: 0.9822 - val_loss: 0.1114 - val_sparse_categorical_accuracy: 0.9702\n",
            "Epoch 6/10\n",
            "7620/7620 [==============================] - 301s 39ms/step - loss: 0.0499 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.1014 - val_sparse_categorical_accuracy: 0.9743\n",
            "Epoch 00006: early stopping\n",
            "847/847 [==============================] - 12s 14ms/step - loss: 0.1014 - sparse_categorical_accuracy: 0.9743\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9743457436561584\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.10141967236995697\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9735717427172014\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giZuNE7HJ21t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "8b3dcd2f-17bf-4b94-cd8f-075c1936a6d8"
      },
      "source": [
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(balancedAccuracies)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {losses[i]} - class-wise Accuracy: {balancedAccuracies[i]}% Accuracy - {baseAccuracies[i]} - Precision: {precisions[i]} - Recall: {recalls[i]} - F1: {f1scores[i]}')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(balancedAccuracies)} (+- {np.std(balancedAccuracies)})')\n",
        "print(f'> Loss: {np.mean(losses)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.09524818509817123 - class-wise Accuracy: 0.9736809674136414% Accuracy - 0.9752325415611267 - Precision: 0.9754273164585813 - Recall: 0.9752325409715045 - F1: 0.9752216129625239\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.0938861295580864 - class-wise Accuracy: 0.9756921460402637% Accuracy - 0.9784069061279297 - Precision: 0.9785380055925875 - Recall: 0.9784069097888676 - F1: 0.9783767218623598\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.10349077731370926 - class-wise Accuracy: 0.9730794832785572% Accuracy - 0.9729430675506592 - Precision: 0.9733860857574821 - Recall: 0.9729430438152892 - F1: 0.9729507354533107\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.08889444172382355 - class-wise Accuracy: 0.9755495507931318% Accuracy - 0.9776309728622437 - Precision: 0.977716723716865 - Recall: 0.9776309475471558 - F1: 0.9776037515980482\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.09104037284851074 - class-wise Accuracy: 0.9722403485002241% Accuracy - 0.9770034551620483 - Precision: 0.9771937017895563 - Recall: 0.9770034328743863 - F1: 0.9769896996687565\n",
            "------------------------------------------------------------------------\n",
            "> Fold 6 - Loss: 0.08785446733236313 - class-wise Accuracy: 0.9730252884686298% Accuracy - 0.9761175513267517 - Precision: 0.9762318208676996 - Recall: 0.976117529806947 - F1: 0.9761143668260939\n",
            "------------------------------------------------------------------------\n",
            "> Fold 7 - Loss: 0.09682947397232056 - class-wise Accuracy: 0.9748201624647035% Accuracy - 0.976006805896759 - Precision: 0.9761492750987099 - Recall: 0.976006791923517 - F1: 0.9759472725678188\n",
            "------------------------------------------------------------------------\n",
            "> Fold 8 - Loss: 0.09183358401060104 - class-wise Accuracy: 0.9750273558961515% Accuracy - 0.9781477451324463 - Precision: 0.9782841771098666 - Recall: 0.9781477243364955 - F1: 0.9780764996101116\n",
            "------------------------------------------------------------------------\n",
            "> Fold 9 - Loss: 0.09331969916820526 - class-wise Accuracy: 0.9733239991184561% Accuracy - 0.9753423929214478 - Precision: 0.975568323707855 - Recall: 0.9753423646229376 - F1: 0.9753351350251154\n",
            "------------------------------------------------------------------------\n",
            "> Fold 10 - Loss: 0.10141967236995697 - class-wise Accuracy: 0.9735717427172014% Accuracy - 0.9743457436561584 - Precision: 0.974720440955849 - Recall: 0.9743457236720682 - F1: 0.9743844414859637\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.9740011044690959 (+- 0.0011237673503534191)\n",
            "> Loss: 0.09438168033957481\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdlcPZOAKtO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}