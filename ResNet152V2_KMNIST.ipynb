{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet152V2_KMNIST.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfkM-Wk6boWg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "456dc861-23de-4ce4-a9db-34b429d4ec15"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import svm, metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "from skimage.transform import resize, rescale\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import data, color\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from numpy import savez_compressed\n",
        "from google.colab import files\n",
        "from numpy import load\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.callbacks import EarlyStopping\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "filename = '/content/gdrive/My Drive/Research2/np_data/xkmnist.npz'\n",
        "x = np.load(filename)['arr_0']\n",
        "\n",
        "filename = '/content/gdrive/My Drive/Research2/np_data/ykmnist.npz'\n",
        "y = np.load(filename)['arr_0']\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "(70000, 56, 56, 1)\n",
            "(70000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8qC0dVJbzkr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f237bb2-8914-45b4-ee1b-31b8857427a9"
      },
      "source": [
        "baseAccuracies = []\n",
        "losses = []\n",
        "balancedAccuracies = []\n",
        "f1scores = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "fold_no = 1\n",
        "callback = EarlyStopping(monitor = 'val_loss', patience = 2, verbose = 1)\n",
        "\n",
        "for train, test in kfold.split(x, y):\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  print(\"Fold number: \" + str(fold_no))\n",
        "  fold_no = fold_no+1\n",
        "  print()\n",
        "\n",
        "  xtrain = x[train]\n",
        "  xtest = x[test]\n",
        "  \n",
        "  model = tf.keras.applications.ResNet152V2(include_top=True, weights=None, input_shape=(56, 56, 1), classes=10, classifier_activation=\"softmax\",)\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=Adam(lr=0.0001), metrics=[\"sparse_categorical_accuracy\"])\n",
        "  model.fit(xtrain, y[train], verbose = 1, validation_data = (xtest, y[test]), epochs = 100, callbacks = [callback], batch_size = 32)\n",
        "\n",
        "  test_loss, test_accuracy = model.evaluate(xtest, y[test])\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  print(\"Test Accuracy:\")\n",
        "  print(test_accuracy)\n",
        "  baseAccuracies.append(test_accuracy)\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  print(\"Test Loss:\")\n",
        "  print(test_loss)\n",
        "  losses.append(test_loss)\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  preds = np.argmax(model.predict(xtest), axis=-1)\n",
        "  preds = preds.reshape(len(xtest), 1)\n",
        "  accs = []\n",
        "  for cls in range(10):\n",
        "    mask = (y[test] == cls)\n",
        "    cls_acc = (preds == cls)[mask].mean() \n",
        "    accs.append(cls_acc)\n",
        "  accs = np.mean(accs)\n",
        "  print(\"Final balanced accuracy:\")\n",
        "  print(accs)\n",
        "  balancedAccuracies.append(accs)\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  f1scores.append(f1_score(y[test], preds, average = 'weighted'))\n",
        "  precisions.append(precision_score(y[test], preds, average = 'weighted'))\n",
        "  recalls.append(recall_score(y[test], preds, average = 'weighted'))\n",
        "  print(\"*********************************************************************************************************************************\")\n",
        "  print()\n",
        "  print()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 1\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 204s 103ms/step - loss: 0.6004 - sparse_categorical_accuracy: 0.8049 - val_loss: 0.3786 - val_sparse_categorical_accuracy: 0.8803\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 202s 102ms/step - loss: 0.1840 - sparse_categorical_accuracy: 0.9430 - val_loss: 0.1259 - val_sparse_categorical_accuracy: 0.9629\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 202s 103ms/step - loss: 0.1057 - sparse_categorical_accuracy: 0.9665 - val_loss: 0.1232 - val_sparse_categorical_accuracy: 0.9644\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0734 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.0899 - val_sparse_categorical_accuracy: 0.9727\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0571 - sparse_categorical_accuracy: 0.9827 - val_loss: 0.0794 - val_sparse_categorical_accuracy: 0.9753\n",
            "Epoch 6/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0460 - sparse_categorical_accuracy: 0.9855 - val_loss: 0.0592 - val_sparse_categorical_accuracy: 0.9829\n",
            "Epoch 7/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0351 - sparse_categorical_accuracy: 0.9892 - val_loss: 0.0542 - val_sparse_categorical_accuracy: 0.9856\n",
            "Epoch 8/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0315 - sparse_categorical_accuracy: 0.9901 - val_loss: 0.0740 - val_sparse_categorical_accuracy: 0.9784\n",
            "Epoch 9/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0244 - sparse_categorical_accuracy: 0.9923 - val_loss: 0.0865 - val_sparse_categorical_accuracy: 0.9756\n",
            "Epoch 00009: early stopping\n",
            "219/219 [==============================] - 7s 32ms/step - loss: 0.0865 - sparse_categorical_accuracy: 0.9756\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9755714535713196\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.08650551736354828\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9755203798112037\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 2\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 203s 103ms/step - loss: 0.5931 - sparse_categorical_accuracy: 0.8061 - val_loss: 0.2544 - val_sparse_categorical_accuracy: 0.9207\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.1766 - sparse_categorical_accuracy: 0.9441 - val_loss: 0.1591 - val_sparse_categorical_accuracy: 0.9519\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0986 - sparse_categorical_accuracy: 0.9696 - val_loss: 0.1153 - val_sparse_categorical_accuracy: 0.9634\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 202s 102ms/step - loss: 0.0688 - sparse_categorical_accuracy: 0.9786 - val_loss: 0.0970 - val_sparse_categorical_accuracy: 0.9717\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0547 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.0903 - val_sparse_categorical_accuracy: 0.9751\n",
            "Epoch 6/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0425 - sparse_categorical_accuracy: 0.9866 - val_loss: 0.0999 - val_sparse_categorical_accuracy: 0.9727\n",
            "Epoch 7/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0363 - sparse_categorical_accuracy: 0.9889 - val_loss: 0.0808 - val_sparse_categorical_accuracy: 0.9806\n",
            "Epoch 8/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0285 - sparse_categorical_accuracy: 0.9915 - val_loss: 0.1014 - val_sparse_categorical_accuracy: 0.9729\n",
            "Epoch 9/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0248 - sparse_categorical_accuracy: 0.9926 - val_loss: 0.0769 - val_sparse_categorical_accuracy: 0.9789\n",
            "Epoch 10/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0206 - sparse_categorical_accuracy: 0.9939 - val_loss: 0.0650 - val_sparse_categorical_accuracy: 0.9824\n",
            "Epoch 11/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0201 - sparse_categorical_accuracy: 0.9940 - val_loss: 0.0811 - val_sparse_categorical_accuracy: 0.9776\n",
            "Epoch 12/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0166 - sparse_categorical_accuracy: 0.9951 - val_loss: 0.0503 - val_sparse_categorical_accuracy: 0.9866\n",
            "Epoch 13/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0147 - sparse_categorical_accuracy: 0.9953 - val_loss: 0.0822 - val_sparse_categorical_accuracy: 0.9810\n",
            "Epoch 14/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0123 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0527 - val_sparse_categorical_accuracy: 0.9866\n",
            "Epoch 00014: early stopping\n",
            "219/219 [==============================] - 7s 33ms/step - loss: 0.0527 - sparse_categorical_accuracy: 0.9866\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9865714311599731\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.052710652351379395\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.986637154957692\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 3\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 203s 103ms/step - loss: 0.5887 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.2846 - val_sparse_categorical_accuracy: 0.9090\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.1756 - sparse_categorical_accuracy: 0.9455 - val_loss: 0.1978 - val_sparse_categorical_accuracy: 0.9391\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.1025 - sparse_categorical_accuracy: 0.9680 - val_loss: 0.1785 - val_sparse_categorical_accuracy: 0.9483\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0717 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.0990 - val_sparse_categorical_accuracy: 0.9716\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0547 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.0750 - val_sparse_categorical_accuracy: 0.9773\n",
            "Epoch 6/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0460 - sparse_categorical_accuracy: 0.9857 - val_loss: 0.0633 - val_sparse_categorical_accuracy: 0.9821\n",
            "Epoch 7/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0350 - sparse_categorical_accuracy: 0.9888 - val_loss: 0.0787 - val_sparse_categorical_accuracy: 0.9769\n",
            "Epoch 8/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0303 - sparse_categorical_accuracy: 0.9911 - val_loss: 0.0757 - val_sparse_categorical_accuracy: 0.9773\n",
            "Epoch 00008: early stopping\n",
            "219/219 [==============================] - 7s 33ms/step - loss: 0.0757 - sparse_categorical_accuracy: 0.9773\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9772857427597046\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.07572481036186218\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9772912336970085\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 4\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 203s 103ms/step - loss: 0.5834 - sparse_categorical_accuracy: 0.8103 - val_loss: 0.2879 - val_sparse_categorical_accuracy: 0.9103\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 200s 101ms/step - loss: 0.1758 - sparse_categorical_accuracy: 0.9455 - val_loss: 0.1702 - val_sparse_categorical_accuracy: 0.9504\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0971 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.1025 - val_sparse_categorical_accuracy: 0.9716\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 200s 101ms/step - loss: 0.0693 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.1106 - val_sparse_categorical_accuracy: 0.9669\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0544 - sparse_categorical_accuracy: 0.9825 - val_loss: 0.0926 - val_sparse_categorical_accuracy: 0.9723\n",
            "Epoch 6/100\n",
            "1969/1969 [==============================] - 200s 101ms/step - loss: 0.0436 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.0867 - val_sparse_categorical_accuracy: 0.9746\n",
            "Epoch 7/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0356 - sparse_categorical_accuracy: 0.9895 - val_loss: 0.1065 - val_sparse_categorical_accuracy: 0.9689\n",
            "Epoch 8/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0296 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.0721 - val_sparse_categorical_accuracy: 0.9789\n",
            "Epoch 9/100\n",
            "1969/1969 [==============================] - 200s 101ms/step - loss: 0.0242 - sparse_categorical_accuracy: 0.9926 - val_loss: 0.0513 - val_sparse_categorical_accuracy: 0.9860\n",
            "Epoch 10/100\n",
            "1969/1969 [==============================] - 199s 101ms/step - loss: 0.0215 - sparse_categorical_accuracy: 0.9935 - val_loss: 0.0487 - val_sparse_categorical_accuracy: 0.9863\n",
            "Epoch 11/100\n",
            "1969/1969 [==============================] - 199s 101ms/step - loss: 0.0179 - sparse_categorical_accuracy: 0.9943 - val_loss: 0.0543 - val_sparse_categorical_accuracy: 0.9864\n",
            "Epoch 12/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0166 - sparse_categorical_accuracy: 0.9949 - val_loss: 0.0576 - val_sparse_categorical_accuracy: 0.9847\n",
            "Epoch 00012: early stopping\n",
            "219/219 [==============================] - 7s 33ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9847\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9847142696380615\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.057551268488168716\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.984635213410108\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 5\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 203s 103ms/step - loss: 0.5833 - sparse_categorical_accuracy: 0.8105 - val_loss: 0.3282 - val_sparse_categorical_accuracy: 0.8973\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.1767 - sparse_categorical_accuracy: 0.9450 - val_loss: 0.1334 - val_sparse_categorical_accuracy: 0.9601\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0975 - sparse_categorical_accuracy: 0.9703 - val_loss: 0.1108 - val_sparse_categorical_accuracy: 0.9653\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0728 - sparse_categorical_accuracy: 0.9776 - val_loss: 0.0988 - val_sparse_categorical_accuracy: 0.9714\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0530 - sparse_categorical_accuracy: 0.9835 - val_loss: 0.0947 - val_sparse_categorical_accuracy: 0.9753\n",
            "Epoch 6/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0449 - sparse_categorical_accuracy: 0.9857 - val_loss: 0.0760 - val_sparse_categorical_accuracy: 0.9796\n",
            "Epoch 7/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0350 - sparse_categorical_accuracy: 0.9893 - val_loss: 0.0811 - val_sparse_categorical_accuracy: 0.9764\n",
            "Epoch 8/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0291 - sparse_categorical_accuracy: 0.9911 - val_loss: 0.0556 - val_sparse_categorical_accuracy: 0.9854\n",
            "Epoch 9/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0246 - sparse_categorical_accuracy: 0.9926 - val_loss: 0.0529 - val_sparse_categorical_accuracy: 0.9851\n",
            "Epoch 10/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0221 - sparse_categorical_accuracy: 0.9937 - val_loss: 0.0517 - val_sparse_categorical_accuracy: 0.9849\n",
            "Epoch 11/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0200 - sparse_categorical_accuracy: 0.9941 - val_loss: 0.0597 - val_sparse_categorical_accuracy: 0.9833\n",
            "Epoch 12/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0145 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0798 - val_sparse_categorical_accuracy: 0.9810\n",
            "Epoch 00012: early stopping\n",
            "219/219 [==============================] - 7s 33ms/step - loss: 0.0798 - sparse_categorical_accuracy: 0.9810\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9810000061988831\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.07978703081607819\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9812003630406656\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 6\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 203s 103ms/step - loss: 0.5778 - sparse_categorical_accuracy: 0.8120 - val_loss: 0.2605 - val_sparse_categorical_accuracy: 0.9147\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.1792 - sparse_categorical_accuracy: 0.9435 - val_loss: 0.1408 - val_sparse_categorical_accuracy: 0.9546\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.1015 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.0946 - val_sparse_categorical_accuracy: 0.9711\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0719 - sparse_categorical_accuracy: 0.9779 - val_loss: 0.0952 - val_sparse_categorical_accuracy: 0.9706\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0548 - sparse_categorical_accuracy: 0.9829 - val_loss: 0.0579 - val_sparse_categorical_accuracy: 0.9836\n",
            "Epoch 6/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0437 - sparse_categorical_accuracy: 0.9869 - val_loss: 0.0749 - val_sparse_categorical_accuracy: 0.9774\n",
            "Epoch 7/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0365 - sparse_categorical_accuracy: 0.9887 - val_loss: 0.0536 - val_sparse_categorical_accuracy: 0.9849\n",
            "Epoch 8/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0298 - sparse_categorical_accuracy: 0.9905 - val_loss: 0.0475 - val_sparse_categorical_accuracy: 0.9881\n",
            "Epoch 9/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0255 - sparse_categorical_accuracy: 0.9924 - val_loss: 0.0809 - val_sparse_categorical_accuracy: 0.9789\n",
            "Epoch 10/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0222 - sparse_categorical_accuracy: 0.9934 - val_loss: 0.0794 - val_sparse_categorical_accuracy: 0.9790\n",
            "Epoch 00010: early stopping\n",
            "219/219 [==============================] - 7s 33ms/step - loss: 0.0794 - sparse_categorical_accuracy: 0.9790\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9789999723434448\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.07938481867313385\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9792846707521434\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 7\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 203s 103ms/step - loss: 0.6008 - sparse_categorical_accuracy: 0.8028 - val_loss: 0.2924 - val_sparse_categorical_accuracy: 0.9100\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.1871 - sparse_categorical_accuracy: 0.9413 - val_loss: 0.2174 - val_sparse_categorical_accuracy: 0.9364\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 203s 103ms/step - loss: 0.1011 - sparse_categorical_accuracy: 0.9674 - val_loss: 0.0893 - val_sparse_categorical_accuracy: 0.9746\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0732 - sparse_categorical_accuracy: 0.9772 - val_loss: 0.0858 - val_sparse_categorical_accuracy: 0.9741\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0543 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.0901 - val_sparse_categorical_accuracy: 0.9749\n",
            "Epoch 6/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0428 - sparse_categorical_accuracy: 0.9866 - val_loss: 0.0736 - val_sparse_categorical_accuracy: 0.9794\n",
            "Epoch 7/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0370 - sparse_categorical_accuracy: 0.9890 - val_loss: 0.0532 - val_sparse_categorical_accuracy: 0.9841\n",
            "Epoch 8/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0296 - sparse_categorical_accuracy: 0.9912 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9823\n",
            "Epoch 9/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0254 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.0577 - val_sparse_categorical_accuracy: 0.9843\n",
            "Epoch 00009: early stopping\n",
            "219/219 [==============================] - 7s 33ms/step - loss: 0.0577 - sparse_categorical_accuracy: 0.9843\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9842857122421265\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.05772214010357857\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9843436213329358\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 8\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 204s 104ms/step - loss: 0.5735 - sparse_categorical_accuracy: 0.8142 - val_loss: 0.2852 - val_sparse_categorical_accuracy: 0.9114\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.1787 - sparse_categorical_accuracy: 0.9436 - val_loss: 0.1335 - val_sparse_categorical_accuracy: 0.9586\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0996 - sparse_categorical_accuracy: 0.9684 - val_loss: 0.1039 - val_sparse_categorical_accuracy: 0.9693\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0718 - sparse_categorical_accuracy: 0.9776 - val_loss: 0.2114 - val_sparse_categorical_accuracy: 0.9433\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0531 - sparse_categorical_accuracy: 0.9842 - val_loss: 0.0975 - val_sparse_categorical_accuracy: 0.9711\n",
            "Epoch 6/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0454 - sparse_categorical_accuracy: 0.9856 - val_loss: 0.0840 - val_sparse_categorical_accuracy: 0.9734\n",
            "Epoch 7/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0361 - sparse_categorical_accuracy: 0.9888 - val_loss: 0.0590 - val_sparse_categorical_accuracy: 0.9827\n",
            "Epoch 8/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0294 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.0665 - val_sparse_categorical_accuracy: 0.9833\n",
            "Epoch 9/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0261 - sparse_categorical_accuracy: 0.9919 - val_loss: 0.0740 - val_sparse_categorical_accuracy: 0.9807\n",
            "Epoch 00009: early stopping\n",
            "219/219 [==============================] - 7s 33ms/step - loss: 0.0740 - sparse_categorical_accuracy: 0.9807\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9807142615318298\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.07401879876852036\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9808668542686011\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 9\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 204s 104ms/step - loss: 0.5844 - sparse_categorical_accuracy: 0.8102 - val_loss: 0.2745 - val_sparse_categorical_accuracy: 0.9104\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.1779 - sparse_categorical_accuracy: 0.9442 - val_loss: 0.1870 - val_sparse_categorical_accuracy: 0.9420\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0987 - sparse_categorical_accuracy: 0.9689 - val_loss: 0.1089 - val_sparse_categorical_accuracy: 0.9677\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 202s 102ms/step - loss: 0.0700 - sparse_categorical_accuracy: 0.9782 - val_loss: 0.0842 - val_sparse_categorical_accuracy: 0.9746\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 202s 102ms/step - loss: 0.0553 - sparse_categorical_accuracy: 0.9829 - val_loss: 0.1042 - val_sparse_categorical_accuracy: 0.9690\n",
            "Epoch 6/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0420 - sparse_categorical_accuracy: 0.9872 - val_loss: 0.0827 - val_sparse_categorical_accuracy: 0.9783\n",
            "Epoch 7/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0361 - sparse_categorical_accuracy: 0.9891 - val_loss: 0.0592 - val_sparse_categorical_accuracy: 0.9819\n",
            "Epoch 8/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0293 - sparse_categorical_accuracy: 0.9913 - val_loss: 0.0525 - val_sparse_categorical_accuracy: 0.9847\n",
            "Epoch 9/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0250 - sparse_categorical_accuracy: 0.9927 - val_loss: 0.0513 - val_sparse_categorical_accuracy: 0.9849\n",
            "Epoch 10/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0206 - sparse_categorical_accuracy: 0.9938 - val_loss: 0.0640 - val_sparse_categorical_accuracy: 0.9850\n",
            "Epoch 11/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0198 - sparse_categorical_accuracy: 0.9940 - val_loss: 0.0526 - val_sparse_categorical_accuracy: 0.9849\n",
            "Epoch 00011: early stopping\n",
            "219/219 [==============================] - 7s 33ms/step - loss: 0.0526 - sparse_categorical_accuracy: 0.9849\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9848571419715881\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.052616238594055176\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9848041449593252\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 10\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 202s 103ms/step - loss: 0.6061 - sparse_categorical_accuracy: 0.8011 - val_loss: 0.2556 - val_sparse_categorical_accuracy: 0.9169\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.1847 - sparse_categorical_accuracy: 0.9418 - val_loss: 0.1460 - val_sparse_categorical_accuracy: 0.9563\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.1034 - sparse_categorical_accuracy: 0.9678 - val_loss: 0.1612 - val_sparse_categorical_accuracy: 0.9541\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0708 - sparse_categorical_accuracy: 0.9779 - val_loss: 0.1038 - val_sparse_categorical_accuracy: 0.9676\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 200s 101ms/step - loss: 0.0568 - sparse_categorical_accuracy: 0.9825 - val_loss: 0.0696 - val_sparse_categorical_accuracy: 0.9787\n",
            "Epoch 6/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0454 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0637 - val_sparse_categorical_accuracy: 0.9796\n",
            "Epoch 7/100\n",
            "1969/1969 [==============================] - 200s 101ms/step - loss: 0.0371 - sparse_categorical_accuracy: 0.9889 - val_loss: 0.1031 - val_sparse_categorical_accuracy: 0.9709\n",
            "Epoch 8/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0321 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.0488 - val_sparse_categorical_accuracy: 0.9851\n",
            "Epoch 9/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0242 - sparse_categorical_accuracy: 0.9924 - val_loss: 0.0545 - val_sparse_categorical_accuracy: 0.9851\n",
            "Epoch 10/100\n",
            "1969/1969 [==============================] - 201s 102ms/step - loss: 0.0223 - sparse_categorical_accuracy: 0.9930 - val_loss: 0.0447 - val_sparse_categorical_accuracy: 0.9869\n",
            "Epoch 11/100\n",
            "1969/1969 [==============================] - 200s 102ms/step - loss: 0.0193 - sparse_categorical_accuracy: 0.9941 - val_loss: 0.0484 - val_sparse_categorical_accuracy: 0.9854\n",
            "Epoch 12/100\n",
            "1969/1969 [==============================] - 199s 101ms/step - loss: 0.0153 - sparse_categorical_accuracy: 0.9952 - val_loss: 0.0595 - val_sparse_categorical_accuracy: 0.9861\n",
            "Epoch 00012: early stopping\n",
            "219/219 [==============================] - 7s 33ms/step - loss: 0.0595 - sparse_categorical_accuracy: 0.9861\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9861428737640381\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.05953708663582802\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.986182243238917\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbdI7yFAb3XQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "4af383be-72c0-4253-cc56-b1fcbfba596c"
      },
      "source": [
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(balancedAccuracies)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {losses[i]} - class-wise Accuracy: {balancedAccuracies[i]}% Accuracy - {baseAccuracies[i]} - Precision: {precisions[i]} - Recall: {recalls[i]} - F1: {f1scores[i]}')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(balancedAccuracies)} (+- {np.std(balancedAccuracies)})')\n",
        "print(f'> Loss: {np.mean(losses)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.08650551736354828 - class-wise Accuracy: 0.9755203798112037% Accuracy - 0.9755714535713196 - Precision: 0.9760462063293195 - Recall: 0.9755714285714285 - F1: 0.9755798177275955\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.052710652351379395 - class-wise Accuracy: 0.986637154957692% Accuracy - 0.9865714311599731 - Precision: 0.986621189755759 - Recall: 0.9865714285714285 - F1: 0.9865731244851343\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.07572481036186218 - class-wise Accuracy: 0.9772912336970085% Accuracy - 0.9772857427597046 - Precision: 0.9775169367618598 - Recall: 0.9772857142857143 - F1: 0.9773034292234495\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.057551268488168716 - class-wise Accuracy: 0.984635213410108% Accuracy - 0.9847142696380615 - Precision: 0.9847916237424175 - Recall: 0.9847142857142858 - F1: 0.9847056336568052\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.07978703081607819 - class-wise Accuracy: 0.9812003630406656% Accuracy - 0.9810000061988831 - Precision: 0.9813793191005031 - Recall: 0.981 - F1: 0.9810047904471108\n",
            "------------------------------------------------------------------------\n",
            "> Fold 6 - Loss: 0.07938481867313385 - class-wise Accuracy: 0.9792846707521434% Accuracy - 0.9789999723434448 - Precision: 0.9793355632606893 - Recall: 0.979 - F1: 0.9789684198533183\n",
            "------------------------------------------------------------------------\n",
            "> Fold 7 - Loss: 0.05772214010357857 - class-wise Accuracy: 0.9843436213329358% Accuracy - 0.9842857122421265 - Precision: 0.9843770102870527 - Recall: 0.9842857142857143 - F1: 0.984292614481434\n",
            "------------------------------------------------------------------------\n",
            "> Fold 8 - Loss: 0.07401879876852036 - class-wise Accuracy: 0.9808668542686011% Accuracy - 0.9807142615318298 - Precision: 0.9813785587399304 - Recall: 0.9807142857142858 - F1: 0.9808182120117489\n",
            "------------------------------------------------------------------------\n",
            "> Fold 9 - Loss: 0.052616238594055176 - class-wise Accuracy: 0.9848041449593252% Accuracy - 0.9848571419715881 - Precision: 0.9849086061168142 - Recall: 0.9848571428571429 - F1: 0.9848692150182701\n",
            "------------------------------------------------------------------------\n",
            "> Fold 10 - Loss: 0.05953708663582802 - class-wise Accuracy: 0.986182243238917% Accuracy - 0.9861428737640381 - Precision: 0.986182035149417 - Recall: 0.9861428571428571 - F1: 0.9861346269481573\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.9820765879468599 (+- 0.0036426673801462786)\n",
            "> Loss: 0.06755583621561527\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp1zgELQcG7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}