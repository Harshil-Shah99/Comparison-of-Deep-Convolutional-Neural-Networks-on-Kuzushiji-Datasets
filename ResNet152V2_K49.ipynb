{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet152V2_K49.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8E_OLVWMA1o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "6ce9b639-e37c-4846-c88b-0de765827700"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import svm, metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "from skimage.transform import resize, rescale\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import data, color\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from numpy import savez_compressed\n",
        "from google.colab import files\n",
        "from numpy import load\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.callbacks import EarlyStopping\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "filename = '/content/gdrive/My Drive/Research2/np_data/x.npz'\n",
        "x = np.load(filename)['arr_0']\n",
        "\n",
        "filename = '/content/gdrive/My Drive/Research2/np_data/y.npz'\n",
        "y = np.load(filename)['arr_0']\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "(270912, 56, 56, 1)\n",
            "(270912, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htS-6KjWMW8n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "27787457-4fef-479f-ab8f-f07aef1b6fb1"
      },
      "source": [
        "baseAccuracies = []\n",
        "losses = []\n",
        "balancedAccuracies = []\n",
        "f1scores = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "fold_no = 1\n",
        "callback = EarlyStopping(monitor = 'val_loss', patience = 2, verbose = 1)\n",
        "\n",
        "for train, test in kfold.split(x, y):\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  print(\"Fold number: \" + str(fold_no))\n",
        "  fold_no = fold_no+1\n",
        "  print()\n",
        "\n",
        "  xtrain = x[train]\n",
        "  xtest = x[test]\n",
        "  \n",
        "  model = tf.keras.applications.ResNet152V2(include_top=True, weights=None, input_shape=(56, 56, 1), classes=49, classifier_activation=\"softmax\",)\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=Adam(lr=0.0001), metrics=[\"sparse_categorical_accuracy\"])\n",
        "  model.fit(xtrain, y[train], verbose = 1, validation_data = (xtest, y[test]), epochs = 100, callbacks = [callback], batch_size = 32)\n",
        "\n",
        "  test_loss, test_accuracy = model.evaluate(xtest, y[test])\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  print(\"Test Accuracy:\")\n",
        "  print(test_accuracy)\n",
        "  baseAccuracies.append(test_accuracy)\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  print(\"Test Loss:\")\n",
        "  print(test_loss)\n",
        "  losses.append(test_loss)\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  preds = np.argmax(model.predict(xtest), axis=-1)\n",
        "  preds = preds.reshape(len(xtest), 1)\n",
        "  accs = []\n",
        "  for cls in range(49):\n",
        "    mask = (y[test] == cls)\n",
        "    cls_acc = (preds == cls)[mask].mean() \n",
        "    accs.append(cls_acc)\n",
        "  accs = np.mean(accs)\n",
        "  print(\"Final balanced accuracy:\")\n",
        "  print(accs)\n",
        "  balancedAccuracies.append(accs)\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  f1scores.append(f1_score(y[test], preds, average = 'weighted'))\n",
        "  precisions.append(precision_score(y[test], preds, average = 'weighted'))\n",
        "  recalls.append(recall_score(y[test], preds, average = 'weighted'))\n",
        "  print(\"*********************************************************************************************************************************\")\n",
        "  print()\n",
        "  print()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 1\n",
            "\n",
            "Epoch 1/100\n",
            "7620/7620 [==============================] - 741s 97ms/step - loss: 0.6519 - sparse_categorical_accuracy: 0.8221 - val_loss: 0.2719 - val_sparse_categorical_accuracy: 0.9222\n",
            "Epoch 2/100\n",
            "7620/7620 [==============================] - 736s 97ms/step - loss: 0.1839 - sparse_categorical_accuracy: 0.9481 - val_loss: 0.1498 - val_sparse_categorical_accuracy: 0.9593\n",
            "Epoch 3/100\n",
            "7620/7620 [==============================] - 740s 97ms/step - loss: 0.1217 - sparse_categorical_accuracy: 0.9651 - val_loss: 0.1352 - val_sparse_categorical_accuracy: 0.9626\n",
            "Epoch 4/100\n",
            "7620/7620 [==============================] - 737s 97ms/step - loss: 0.0895 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.1142 - val_sparse_categorical_accuracy: 0.9679\n",
            "Epoch 5/100\n",
            "7620/7620 [==============================] - 735s 96ms/step - loss: 0.0704 - sparse_categorical_accuracy: 0.9791 - val_loss: 0.1032 - val_sparse_categorical_accuracy: 0.9742\n",
            "Epoch 6/100\n",
            "7620/7620 [==============================] - 743s 97ms/step - loss: 0.0577 - sparse_categorical_accuracy: 0.9828 - val_loss: 0.1028 - val_sparse_categorical_accuracy: 0.9725\n",
            "Epoch 7/100\n",
            "7620/7620 [==============================] - 745s 98ms/step - loss: 0.0475 - sparse_categorical_accuracy: 0.9855 - val_loss: 0.0985 - val_sparse_categorical_accuracy: 0.9750\n",
            "Epoch 8/100\n",
            "7620/7620 [==============================] - 746s 98ms/step - loss: 0.0404 - sparse_categorical_accuracy: 0.9874 - val_loss: 0.0918 - val_sparse_categorical_accuracy: 0.9769\n",
            "Epoch 9/100\n",
            "7620/7620 [==============================] - 746s 98ms/step - loss: 0.0348 - sparse_categorical_accuracy: 0.9893 - val_loss: 0.0924 - val_sparse_categorical_accuracy: 0.9778\n",
            "Epoch 10/100\n",
            "7620/7620 [==============================] - 746s 98ms/step - loss: 0.0310 - sparse_categorical_accuracy: 0.9902 - val_loss: 0.0950 - val_sparse_categorical_accuracy: 0.9769\n",
            "Epoch 00010: early stopping\n",
            "847/847 [==============================] - 27s 32ms/step - loss: 0.0950 - sparse_categorical_accuracy: 0.9769\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9768935441970825\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.09503109008073807\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9736071059357138\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 2\n",
            "\n",
            "Epoch 1/100\n",
            "7620/7620 [==============================] - 758s 99ms/step - loss: 0.6415 - sparse_categorical_accuracy: 0.8252 - val_loss: 0.2500 - val_sparse_categorical_accuracy: 0.9305\n",
            "Epoch 2/100\n",
            "7620/7620 [==============================] - 756s 99ms/step - loss: 0.1830 - sparse_categorical_accuracy: 0.9480 - val_loss: 0.2170 - val_sparse_categorical_accuracy: 0.9375\n",
            "Epoch 3/100\n",
            "7620/7620 [==============================] - 754s 99ms/step - loss: 0.1210 - sparse_categorical_accuracy: 0.9653 - val_loss: 0.1180 - val_sparse_categorical_accuracy: 0.9657\n",
            "Epoch 4/100\n",
            "7620/7620 [==============================] - 754s 99ms/step - loss: 0.0908 - sparse_categorical_accuracy: 0.9732 - val_loss: 0.1025 - val_sparse_categorical_accuracy: 0.9716\n",
            "Epoch 5/100\n",
            "7620/7620 [==============================] - 753s 99ms/step - loss: 0.0696 - sparse_categorical_accuracy: 0.9793 - val_loss: 0.1031 - val_sparse_categorical_accuracy: 0.9718\n",
            "Epoch 6/100\n",
            "7620/7620 [==============================] - 752s 99ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9827 - val_loss: 0.1021 - val_sparse_categorical_accuracy: 0.9721\n",
            "Epoch 7/100\n",
            "7620/7620 [==============================] - 754s 99ms/step - loss: 0.0485 - sparse_categorical_accuracy: 0.9853 - val_loss: 0.0976 - val_sparse_categorical_accuracy: 0.9743\n",
            "Epoch 8/100\n",
            "7620/7620 [==============================] - 754s 99ms/step - loss: 0.0401 - sparse_categorical_accuracy: 0.9876 - val_loss: 0.1037 - val_sparse_categorical_accuracy: 0.9745\n",
            "Epoch 9/100\n",
            "7620/7620 [==============================] - 755s 99ms/step - loss: 0.0351 - sparse_categorical_accuracy: 0.9892 - val_loss: 0.1007 - val_sparse_categorical_accuracy: 0.9747\n",
            "Epoch 00009: early stopping\n",
            "847/847 [==============================] - 27s 32ms/step - loss: 0.1007 - sparse_categorical_accuracy: 0.9747\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9746788740158081\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.10068406164646149\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9732216166733227\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 3\n",
            "\n",
            "Epoch 1/100\n",
            "7620/7620 [==============================] - 757s 99ms/step - loss: 0.6232 - sparse_categorical_accuracy: 0.8302 - val_loss: 0.2803 - val_sparse_categorical_accuracy: 0.9202\n",
            "Epoch 2/100\n",
            "7620/7620 [==============================] - 752s 99ms/step - loss: 0.1811 - sparse_categorical_accuracy: 0.9488 - val_loss: 0.1506 - val_sparse_categorical_accuracy: 0.9582\n",
            "Epoch 3/100\n",
            "7620/7620 [==============================] - 749s 98ms/step - loss: 0.1208 - sparse_categorical_accuracy: 0.9658 - val_loss: 0.1314 - val_sparse_categorical_accuracy: 0.9629\n",
            "Epoch 4/100\n",
            "7620/7620 [==============================] - 749s 98ms/step - loss: 0.0898 - sparse_categorical_accuracy: 0.9739 - val_loss: 0.1190 - val_sparse_categorical_accuracy: 0.9683\n",
            "Epoch 5/100\n",
            "7620/7620 [==============================] - 751s 99ms/step - loss: 0.0700 - sparse_categorical_accuracy: 0.9791 - val_loss: 0.1080 - val_sparse_categorical_accuracy: 0.9723\n",
            "Epoch 6/100\n",
            "7620/7620 [==============================] - 746s 98ms/step - loss: 0.0573 - sparse_categorical_accuracy: 0.9828 - val_loss: 0.0941 - val_sparse_categorical_accuracy: 0.9763\n",
            "Epoch 7/100\n",
            "7620/7620 [==============================] - 743s 97ms/step - loss: 0.0473 - sparse_categorical_accuracy: 0.9854 - val_loss: 0.1090 - val_sparse_categorical_accuracy: 0.9724\n",
            "Epoch 8/100\n",
            "7620/7620 [==============================] - 743s 98ms/step - loss: 0.0396 - sparse_categorical_accuracy: 0.9879 - val_loss: 0.1020 - val_sparse_categorical_accuracy: 0.9758\n",
            "Epoch 00008: early stopping\n",
            "847/847 [==============================] - 27s 32ms/step - loss: 0.1020 - sparse_categorical_accuracy: 0.9758\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9757853150367737\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.10202111303806305\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9739631470904816\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 4\n",
            "\n",
            "Epoch 1/100\n",
            "7620/7620 [==============================] - 747s 98ms/step - loss: 0.6281 - sparse_categorical_accuracy: 0.8290 - val_loss: 0.2578 - val_sparse_categorical_accuracy: 0.9246\n",
            "Epoch 2/100\n",
            "7620/7620 [==============================] - 748s 98ms/step - loss: 0.1828 - sparse_categorical_accuracy: 0.9484 - val_loss: 0.1653 - val_sparse_categorical_accuracy: 0.9548\n",
            "Epoch 3/100\n",
            "7620/7620 [==============================] - 755s 99ms/step - loss: 0.1209 - sparse_categorical_accuracy: 0.9653 - val_loss: 0.1333 - val_sparse_categorical_accuracy: 0.9619\n",
            "Epoch 4/100\n",
            "7620/7620 [==============================] - 755s 99ms/step - loss: 0.0898 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1260 - val_sparse_categorical_accuracy: 0.9652\n",
            "Epoch 5/100\n",
            "7620/7620 [==============================] - 756s 99ms/step - loss: 0.0700 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.1196 - val_sparse_categorical_accuracy: 0.9672\n",
            "Epoch 6/100\n",
            "7620/7620 [==============================] - 756s 99ms/step - loss: 0.0571 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.0894 - val_sparse_categorical_accuracy: 0.9762\n",
            "Epoch 7/100\n",
            "7620/7620 [==============================] - 754s 99ms/step - loss: 0.0470 - sparse_categorical_accuracy: 0.9857 - val_loss: 0.1048 - val_sparse_categorical_accuracy: 0.9738\n",
            "Epoch 8/100\n",
            "7620/7620 [==============================] - 755s 99ms/step - loss: 0.0401 - sparse_categorical_accuracy: 0.9873 - val_loss: 0.1080 - val_sparse_categorical_accuracy: 0.9736\n",
            "Epoch 00008: early stopping\n",
            "847/847 [==============================] - 28s 33ms/step - loss: 0.1080 - sparse_categorical_accuracy: 0.9736\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9736074805259705\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.10800701379776001\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9714009549707805\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 5\n",
            "\n",
            "Epoch 1/100\n",
            "7620/7620 [==============================] - 757s 99ms/step - loss: 0.6312 - sparse_categorical_accuracy: 0.8270 - val_loss: 0.2465 - val_sparse_categorical_accuracy: 0.9309\n",
            "Epoch 2/100\n",
            "7620/7620 [==============================] - 755s 99ms/step - loss: 0.1834 - sparse_categorical_accuracy: 0.9482 - val_loss: 0.1606 - val_sparse_categorical_accuracy: 0.9547\n",
            "Epoch 3/100\n",
            "7620/7620 [==============================] - 755s 99ms/step - loss: 0.1209 - sparse_categorical_accuracy: 0.9653 - val_loss: 0.1336 - val_sparse_categorical_accuracy: 0.9619\n",
            "Epoch 4/100\n",
            "7620/7620 [==============================] - 754s 99ms/step - loss: 0.0897 - sparse_categorical_accuracy: 0.9742 - val_loss: 0.1109 - val_sparse_categorical_accuracy: 0.9701\n",
            "Epoch 5/100\n",
            "7620/7620 [==============================] - 753s 99ms/step - loss: 0.0696 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.1182 - val_sparse_categorical_accuracy: 0.9685\n",
            "Epoch 6/100\n",
            "7620/7620 [==============================] - 754s 99ms/step - loss: 0.0579 - sparse_categorical_accuracy: 0.9825 - val_loss: 0.1047 - val_sparse_categorical_accuracy: 0.9734\n",
            "Epoch 7/100\n",
            "7620/7620 [==============================] - 753s 99ms/step - loss: 0.0477 - sparse_categorical_accuracy: 0.9853 - val_loss: 0.0957 - val_sparse_categorical_accuracy: 0.9749\n",
            "Epoch 8/100\n",
            "7620/7620 [==============================] - 754s 99ms/step - loss: 0.0407 - sparse_categorical_accuracy: 0.9877 - val_loss: 0.0973 - val_sparse_categorical_accuracy: 0.9753\n",
            "Epoch 9/100\n",
            "7620/7620 [==============================] - 754s 99ms/step - loss: 0.0359 - sparse_categorical_accuracy: 0.9888 - val_loss: 0.1008 - val_sparse_categorical_accuracy: 0.9749\n",
            "Epoch 00009: early stopping\n",
            "847/847 [==============================] - 28s 33ms/step - loss: 0.1008 - sparse_categorical_accuracy: 0.9749\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9748625159263611\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.10083404183387756\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9716250921322749\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 6\n",
            "\n",
            "Epoch 1/100\n",
            "7620/7620 [==============================] - 757s 99ms/step - loss: 0.6518 - sparse_categorical_accuracy: 0.8221 - val_loss: 0.2353 - val_sparse_categorical_accuracy: 0.9335\n",
            "Epoch 2/100\n",
            "7620/7620 [==============================] - 757s 99ms/step - loss: 0.1836 - sparse_categorical_accuracy: 0.9479 - val_loss: 0.1725 - val_sparse_categorical_accuracy: 0.9530\n",
            "Epoch 3/100\n",
            "7620/7620 [==============================] - 755s 99ms/step - loss: 0.1231 - sparse_categorical_accuracy: 0.9652 - val_loss: 0.1340 - val_sparse_categorical_accuracy: 0.9619\n",
            "Epoch 4/100\n",
            "7620/7620 [==============================] - 758s 99ms/step - loss: 0.0894 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1348 - val_sparse_categorical_accuracy: 0.9614\n",
            "Epoch 5/100\n",
            "7620/7620 [==============================] - 756s 99ms/step - loss: 0.0716 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.0961 - val_sparse_categorical_accuracy: 0.9738\n",
            "Epoch 6/100\n",
            "7620/7620 [==============================] - 753s 99ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9825 - val_loss: 0.1044 - val_sparse_categorical_accuracy: 0.9728\n",
            "Epoch 7/100\n",
            "7620/7620 [==============================] - 752s 99ms/step - loss: 0.0486 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.1147 - val_sparse_categorical_accuracy: 0.9709\n",
            "Epoch 00007: early stopping\n",
            "847/847 [==============================] - 27s 32ms/step - loss: 0.1147 - sparse_categorical_accuracy: 0.9709\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9709128737449646\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.11471229046583176\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9642613846905426\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 7\n",
            "\n",
            "Epoch 1/100\n",
            "7620/7620 [==============================] - 751s 99ms/step - loss: 0.6449 - sparse_categorical_accuracy: 0.8244 - val_loss: 0.2685 - val_sparse_categorical_accuracy: 0.9230\n",
            "Epoch 2/100\n",
            "7620/7620 [==============================] - 750s 98ms/step - loss: 0.1823 - sparse_categorical_accuracy: 0.9484 - val_loss: 0.1628 - val_sparse_categorical_accuracy: 0.9564\n",
            "Epoch 3/100\n",
            "7620/7620 [==============================] - 749s 98ms/step - loss: 0.1214 - sparse_categorical_accuracy: 0.9653 - val_loss: 0.1532 - val_sparse_categorical_accuracy: 0.9585\n",
            "Epoch 4/100\n",
            "7620/7620 [==============================] - 749s 98ms/step - loss: 0.0901 - sparse_categorical_accuracy: 0.9739 - val_loss: 0.1254 - val_sparse_categorical_accuracy: 0.9654\n",
            "Epoch 5/100\n",
            "7620/7620 [==============================] - 749s 98ms/step - loss: 0.0706 - sparse_categorical_accuracy: 0.9791 - val_loss: 0.1040 - val_sparse_categorical_accuracy: 0.9717\n",
            "Epoch 6/100\n",
            "7620/7620 [==============================] - 749s 98ms/step - loss: 0.0565 - sparse_categorical_accuracy: 0.9832 - val_loss: 0.1034 - val_sparse_categorical_accuracy: 0.9731\n",
            "Epoch 7/100\n",
            "7620/7620 [==============================] - 749s 98ms/step - loss: 0.0481 - sparse_categorical_accuracy: 0.9853 - val_loss: 0.0953 - val_sparse_categorical_accuracy: 0.9756\n",
            "Epoch 8/100\n",
            "7620/7620 [==============================] - 749s 98ms/step - loss: 0.0405 - sparse_categorical_accuracy: 0.9876 - val_loss: 0.1018 - val_sparse_categorical_accuracy: 0.9746\n",
            "Epoch 9/100\n",
            "7620/7620 [==============================] - 749s 98ms/step - loss: 0.0355 - sparse_categorical_accuracy: 0.9890 - val_loss: 0.1191 - val_sparse_categorical_accuracy: 0.9728\n",
            "Epoch 00009: early stopping\n",
            "847/847 [==============================] - 27s 32ms/step - loss: 0.1191 - sparse_categorical_accuracy: 0.9728\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9727584719657898\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.11907539516687393\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9667000215783332\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 8\n",
            "\n",
            "Epoch 1/100\n",
            "7620/7620 [==============================] - 751s 99ms/step - loss: 0.6330 - sparse_categorical_accuracy: 0.8258 - val_loss: 0.2617 - val_sparse_categorical_accuracy: 0.9260\n",
            "Epoch 2/100\n",
            "7620/7620 [==============================] - 750s 98ms/step - loss: 0.1811 - sparse_categorical_accuracy: 0.9483 - val_loss: 0.1730 - val_sparse_categorical_accuracy: 0.9511\n",
            "Epoch 3/100\n",
            "7620/7620 [==============================] - 750s 98ms/step - loss: 0.1209 - sparse_categorical_accuracy: 0.9657 - val_loss: 0.1289 - val_sparse_categorical_accuracy: 0.9662\n",
            "Epoch 4/100\n",
            "7620/7620 [==============================] - 749s 98ms/step - loss: 0.0893 - sparse_categorical_accuracy: 0.9739 - val_loss: 0.1184 - val_sparse_categorical_accuracy: 0.9688\n",
            "Epoch 5/100\n",
            "7620/7620 [==============================] - 748s 98ms/step - loss: 0.0703 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1123 - val_sparse_categorical_accuracy: 0.9720\n",
            "Epoch 6/100\n",
            "7620/7620 [==============================] - 749s 98ms/step - loss: 0.0564 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1254 - val_sparse_categorical_accuracy: 0.9678\n",
            "Epoch 7/100\n",
            "7620/7620 [==============================] - 748s 98ms/step - loss: 0.0480 - sparse_categorical_accuracy: 0.9853 - val_loss: 0.0974 - val_sparse_categorical_accuracy: 0.9753\n",
            "Epoch 8/100\n",
            "7620/7620 [==============================] - 746s 98ms/step - loss: 0.0399 - sparse_categorical_accuracy: 0.9877 - val_loss: 0.1021 - val_sparse_categorical_accuracy: 0.9755\n",
            "Epoch 9/100\n",
            "7620/7620 [==============================] - 748s 98ms/step - loss: 0.0352 - sparse_categorical_accuracy: 0.9891 - val_loss: 0.1032 - val_sparse_categorical_accuracy: 0.9763\n",
            "Epoch 00009: early stopping\n",
            "847/847 [==============================] - 26s 31ms/step - loss: 0.1032 - sparse_categorical_accuracy: 0.9763\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9763389825820923\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.10323983430862427\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9725052177990251\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 9\n",
            "\n",
            "Epoch 1/100\n",
            "7620/7620 [==============================] - 750s 98ms/step - loss: 0.6566 - sparse_categorical_accuracy: 0.8201 - val_loss: 0.2313 - val_sparse_categorical_accuracy: 0.9342\n",
            "Epoch 2/100\n",
            "7620/7620 [==============================] - 746s 98ms/step - loss: 0.1804 - sparse_categorical_accuracy: 0.9488 - val_loss: 0.1613 - val_sparse_categorical_accuracy: 0.9555\n",
            "Epoch 3/100\n",
            "7620/7620 [==============================] - 748s 98ms/step - loss: 0.1227 - sparse_categorical_accuracy: 0.9650 - val_loss: 0.1421 - val_sparse_categorical_accuracy: 0.9592\n",
            "Epoch 4/100\n",
            "7620/7620 [==============================] - 748s 98ms/step - loss: 0.0900 - sparse_categorical_accuracy: 0.9739 - val_loss: 0.1116 - val_sparse_categorical_accuracy: 0.9694\n",
            "Epoch 5/100\n",
            "7620/7620 [==============================] - 745s 98ms/step - loss: 0.0711 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.1032 - val_sparse_categorical_accuracy: 0.9728\n",
            "Epoch 6/100\n",
            "7620/7620 [==============================] - 744s 98ms/step - loss: 0.0574 - sparse_categorical_accuracy: 0.9827 - val_loss: 0.0939 - val_sparse_categorical_accuracy: 0.9746\n",
            "Epoch 7/100\n",
            "7620/7620 [==============================] - 746s 98ms/step - loss: 0.0482 - sparse_categorical_accuracy: 0.9854 - val_loss: 0.1075 - val_sparse_categorical_accuracy: 0.9718\n",
            "Epoch 8/100\n",
            "7620/7620 [==============================] - 744s 98ms/step - loss: 0.0401 - sparse_categorical_accuracy: 0.9875 - val_loss: 0.0942 - val_sparse_categorical_accuracy: 0.9765\n",
            "Epoch 00008: early stopping\n",
            "847/847 [==============================] - 27s 31ms/step - loss: 0.0942 - sparse_categorical_accuracy: 0.9765\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9764866828918457\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.09416600316762924\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.974019952818163\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 10\n",
            "\n",
            "Epoch 1/100\n",
            "7620/7620 [==============================] - 747s 98ms/step - loss: 0.6410 - sparse_categorical_accuracy: 0.8258 - val_loss: 0.2206 - val_sparse_categorical_accuracy: 0.9381\n",
            "Epoch 2/100\n",
            "7620/7620 [==============================] - 745s 98ms/step - loss: 0.1834 - sparse_categorical_accuracy: 0.9483 - val_loss: 0.1623 - val_sparse_categorical_accuracy: 0.9546\n",
            "Epoch 3/100\n",
            "7620/7620 [==============================] - 745s 98ms/step - loss: 0.1223 - sparse_categorical_accuracy: 0.9650 - val_loss: 0.1421 - val_sparse_categorical_accuracy: 0.9611\n",
            "Epoch 4/100\n",
            "7620/7620 [==============================] - 746s 98ms/step - loss: 0.0902 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1363 - val_sparse_categorical_accuracy: 0.9624\n",
            "Epoch 5/100\n",
            "7620/7620 [==============================] - 745s 98ms/step - loss: 0.0714 - sparse_categorical_accuracy: 0.9787 - val_loss: 0.0984 - val_sparse_categorical_accuracy: 0.9741\n",
            "Epoch 6/100\n",
            "7620/7620 [==============================] - 746s 98ms/step - loss: 0.0567 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.0956 - val_sparse_categorical_accuracy: 0.9745\n",
            "Epoch 7/100\n",
            "7620/7620 [==============================] - 746s 98ms/step - loss: 0.0490 - sparse_categorical_accuracy: 0.9849 - val_loss: 0.0940 - val_sparse_categorical_accuracy: 0.9763\n",
            "Epoch 8/100\n",
            "7620/7620 [==============================] - 746s 98ms/step - loss: 0.0404 - sparse_categorical_accuracy: 0.9874 - val_loss: 0.0940 - val_sparse_categorical_accuracy: 0.9768\n",
            "Epoch 9/100\n",
            "7620/7620 [==============================] - 747s 98ms/step - loss: 0.0354 - sparse_categorical_accuracy: 0.9892 - val_loss: 0.1042 - val_sparse_categorical_accuracy: 0.9741\n",
            "Epoch 00009: early stopping\n",
            "847/847 [==============================] - 27s 32ms/step - loss: 0.1042 - sparse_categorical_accuracy: 0.9741\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9740504026412964\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.10416015982627869\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9728300651096806\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEc7dVO6MXKs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "ae1ce798-0f82-4183-ff35-a66175704863"
      },
      "source": [
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(balancedAccuracies)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {losses[i]} - class-wise Accuracy: {balancedAccuracies[i]}% Accuracy - {baseAccuracies[i]} - Precision: {precisions[i]} - Recall: {recalls[i]} - F1: {f1scores[i]}')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(balancedAccuracies)} (+- {np.std(balancedAccuracies)})')\n",
        "print(f'> Loss: {np.mean(losses)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.09503109008073807 - class-wise Accuracy: 0.9736071059357138% Accuracy - 0.9768935441970825 - Precision: 0.9771615884434569 - Recall: 0.9768935479108224 - F1: 0.9769258868683723\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.10068406164646149 - class-wise Accuracy: 0.9732216166733227% Accuracy - 0.9746788740158081 - Precision: 0.9749596021876459 - Recall: 0.9746788719917319 - F1: 0.9747129340849797\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.10202111303806305 - class-wise Accuracy: 0.9739631470904816% Accuracy - 0.9757853150367737 - Precision: 0.9759792323379306 - Recall: 0.9757853161566572 - F1: 0.9757942012364673\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.10800701379776001 - class-wise Accuracy: 0.9714009549707805% Accuracy - 0.9736074805259705 - Precision: 0.9737757756224805 - Recall: 0.9736074711158688 - F1: 0.9735812067070895\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.10083404183387756 - class-wise Accuracy: 0.9716250921322749% Accuracy - 0.9748625159263611 - Precision: 0.9750304296869451 - Recall: 0.9748625004614079 - F1: 0.9748778994294934\n",
            "------------------------------------------------------------------------\n",
            "> Fold 6 - Loss: 0.11471229046583176 - class-wise Accuracy: 0.9642613846905426% Accuracy - 0.9709128737449646 - Precision: 0.9714647620714817 - Recall: 0.9709128492857406 - F1: 0.9709295602478805\n",
            "------------------------------------------------------------------------\n",
            "> Fold 7 - Loss: 0.11907539516687393 - class-wise Accuracy: 0.9667000215783332% Accuracy - 0.9727584719657898 - Precision: 0.9731494392831547 - Recall: 0.9727584806762394 - F1: 0.9727130149678543\n",
            "------------------------------------------------------------------------\n",
            "> Fold 8 - Loss: 0.10323983430862427 - class-wise Accuracy: 0.9725052177990251% Accuracy - 0.9763389825820923 - Precision: 0.9766029168053287 - Recall: 0.9763390055738068 - F1: 0.9763606448497808\n",
            "------------------------------------------------------------------------\n",
            "> Fold 9 - Loss: 0.09416600316762924 - class-wise Accuracy: 0.974019952818163% Accuracy - 0.9764866828918457 - Precision: 0.976644352350726 - Recall: 0.9764866560850467 - F1: 0.9764588336935608\n",
            "------------------------------------------------------------------------\n",
            "> Fold 10 - Loss: 0.10416015982627869 - class-wise Accuracy: 0.9728300651096806% Accuracy - 0.9740504026412964 - Precision: 0.974552316287169 - Recall: 0.9740504226495884 - F1: 0.9741470686575714\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.971413455879832 (+- 0.0031303123608923855)\n",
            "> Loss: 0.1041931003332138\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnrcxbkrNunK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}