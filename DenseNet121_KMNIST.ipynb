{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet121_KMNIST.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfkM-Wk6boWg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "e13175db-84e3-480f-a3ea-a8989a931375"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import svm, metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "from skimage.transform import resize, rescale\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import data, color\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from numpy import savez_compressed\n",
        "from google.colab import files\n",
        "from numpy import load\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.callbacks import EarlyStopping\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "filename = '/content/gdrive/My Drive/Research2/np_data/xkmnist.npz'\n",
        "x = np.load(filename)['arr_0']\n",
        "\n",
        "filename = '/content/gdrive/My Drive/Research2/np_data/ykmnist.npz'\n",
        "y = np.load(filename)['arr_0']\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "(70000, 56, 56, 1)\n",
            "(70000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8qC0dVJbzkr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ca5a0ee-e04e-493c-9b76-851ec127c1c9"
      },
      "source": [
        "baseAccuracies = []\n",
        "losses = []\n",
        "balancedAccuracies = []\n",
        "f1scores = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "fold_no = 1\n",
        "callback = EarlyStopping(monitor = 'val_loss', patience = 2, verbose = 1)\n",
        "\n",
        "for train, test in kfold.split(x, y):\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  print(\"Fold number: \" + str(fold_no))\n",
        "  fold_no = fold_no+1\n",
        "  print()\n",
        "\n",
        "  xtrain = x[train]\n",
        "  xtest = x[test]\n",
        "  \n",
        "  model = tf.keras.applications.DenseNet121(include_top=True, weights=None, input_shape=(56, 56, 1), classes=10,)\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=Adam(lr=0.0001), metrics=[\"sparse_categorical_accuracy\"])\n",
        "  model.fit(xtrain, y[train], verbose = 1, validation_data = (xtest, y[test]), epochs = 100, callbacks = [callback], batch_size = 32)\n",
        "\n",
        "  test_loss, test_accuracy = model.evaluate(xtest, y[test])\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  print(\"Test Accuracy:\")\n",
        "  print(test_accuracy)\n",
        "  baseAccuracies.append(test_accuracy)\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  print(\"Test Loss:\")\n",
        "  print(test_loss)\n",
        "  losses.append(test_loss)\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  preds = np.argmax(model.predict(xtest), axis=-1)\n",
        "  preds = preds.reshape(len(xtest), 1)\n",
        "  accs = []\n",
        "  for cls in range(10):\n",
        "    mask = (y[test] == cls)\n",
        "    cls_acc = (preds == cls)[mask].mean() \n",
        "    accs.append(cls_acc)\n",
        "  accs = np.mean(accs)\n",
        "  print(\"Final balanced accuracy:\")\n",
        "  print(accs)\n",
        "  balancedAccuracies.append(accs)\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  f1scores.append(f1_score(y[test], preds, average = 'weighted'))\n",
        "  precisions.append(precision_score(y[test], preds, average = 'weighted'))\n",
        "  recalls.append(recall_score(y[test], preds, average = 'weighted'))\n",
        "  print(\"*********************************************************************************************************************************\")\n",
        "  print()\n",
        "  print()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 1\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 122s 62ms/step - loss: 0.3030 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.1232 - val_sparse_categorical_accuracy: 0.9610\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0834 - sparse_categorical_accuracy: 0.9745 - val_loss: 0.0863 - val_sparse_categorical_accuracy: 0.9756\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0513 - sparse_categorical_accuracy: 0.9835 - val_loss: 0.0676 - val_sparse_categorical_accuracy: 0.9800\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 119s 60ms/step - loss: 0.0390 - sparse_categorical_accuracy: 0.9881 - val_loss: 0.0600 - val_sparse_categorical_accuracy: 0.9824\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 119s 60ms/step - loss: 0.0288 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.0601 - val_sparse_categorical_accuracy: 0.9837\n",
            "Epoch 6/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0253 - sparse_categorical_accuracy: 0.9918 - val_loss: 0.0421 - val_sparse_categorical_accuracy: 0.9881\n",
            "Epoch 7/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0186 - sparse_categorical_accuracy: 0.9940 - val_loss: 0.0656 - val_sparse_categorical_accuracy: 0.9833\n",
            "Epoch 8/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0149 - sparse_categorical_accuracy: 0.9952 - val_loss: 0.0580 - val_sparse_categorical_accuracy: 0.9840\n",
            "Epoch 00008: early stopping\n",
            "219/219 [==============================] - 4s 17ms/step - loss: 0.0580 - sparse_categorical_accuracy: 0.9840\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.984000027179718\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.05796632543206215\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.983936195240951\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 2\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 124s 63ms/step - loss: 0.3086 - sparse_categorical_accuracy: 0.9047 - val_loss: 0.1080 - val_sparse_categorical_accuracy: 0.9666\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 119s 61ms/step - loss: 0.0841 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.0779 - val_sparse_categorical_accuracy: 0.9773\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0532 - sparse_categorical_accuracy: 0.9839 - val_loss: 0.0737 - val_sparse_categorical_accuracy: 0.9767\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 119s 61ms/step - loss: 0.0395 - sparse_categorical_accuracy: 0.9876 - val_loss: 0.0531 - val_sparse_categorical_accuracy: 0.9824\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 119s 60ms/step - loss: 0.0310 - sparse_categorical_accuracy: 0.9905 - val_loss: 0.0702 - val_sparse_categorical_accuracy: 0.9787\n",
            "Epoch 6/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0225 - sparse_categorical_accuracy: 0.9929 - val_loss: 0.0452 - val_sparse_categorical_accuracy: 0.9870\n",
            "Epoch 7/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0192 - sparse_categorical_accuracy: 0.9939 - val_loss: 0.0495 - val_sparse_categorical_accuracy: 0.9829\n",
            "Epoch 8/100\n",
            "1969/1969 [==============================] - 119s 60ms/step - loss: 0.0166 - sparse_categorical_accuracy: 0.9946 - val_loss: 0.0480 - val_sparse_categorical_accuracy: 0.9870\n",
            "Epoch 00008: early stopping\n",
            "219/219 [==============================] - 4s 17ms/step - loss: 0.0480 - sparse_categorical_accuracy: 0.9870\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9869999885559082\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.04799214377999306\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9867653861921145\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 3\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 122s 62ms/step - loss: 0.3063 - sparse_categorical_accuracy: 0.9044 - val_loss: 0.1231 - val_sparse_categorical_accuracy: 0.9629\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0826 - sparse_categorical_accuracy: 0.9749 - val_loss: 0.0688 - val_sparse_categorical_accuracy: 0.9783\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 119s 61ms/step - loss: 0.0513 - sparse_categorical_accuracy: 0.9842 - val_loss: 0.0753 - val_sparse_categorical_accuracy: 0.9751\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0392 - sparse_categorical_accuracy: 0.9881 - val_loss: 0.0484 - val_sparse_categorical_accuracy: 0.9840\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 119s 60ms/step - loss: 0.0301 - sparse_categorical_accuracy: 0.9905 - val_loss: 0.0449 - val_sparse_categorical_accuracy: 0.9877\n",
            "Epoch 6/100\n",
            "1969/1969 [==============================] - 119s 61ms/step - loss: 0.0230 - sparse_categorical_accuracy: 0.9923 - val_loss: 0.0484 - val_sparse_categorical_accuracy: 0.9847\n",
            "Epoch 7/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0188 - sparse_categorical_accuracy: 0.9943 - val_loss: 0.0432 - val_sparse_categorical_accuracy: 0.9870\n",
            "Epoch 8/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0162 - sparse_categorical_accuracy: 0.9947 - val_loss: 0.0384 - val_sparse_categorical_accuracy: 0.9879\n",
            "Epoch 9/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0154 - sparse_categorical_accuracy: 0.9951 - val_loss: 0.0322 - val_sparse_categorical_accuracy: 0.9896\n",
            "Epoch 10/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0113 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0307 - val_sparse_categorical_accuracy: 0.9924\n",
            "Epoch 11/100\n",
            "1969/1969 [==============================] - 119s 60ms/step - loss: 0.0120 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.0328 - val_sparse_categorical_accuracy: 0.9909\n",
            "Epoch 12/100\n",
            "1969/1969 [==============================] - 119s 61ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0489 - val_sparse_categorical_accuracy: 0.9874\n",
            "Epoch 00012: early stopping\n",
            "219/219 [==============================] - 4s 17ms/step - loss: 0.0489 - sparse_categorical_accuracy: 0.9874\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9874285459518433\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.04888124763965607\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9872888000876913\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 4\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.3086 - sparse_categorical_accuracy: 0.9040 - val_loss: 0.1028 - val_sparse_categorical_accuracy: 0.9681\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0805 - sparse_categorical_accuracy: 0.9751 - val_loss: 0.0670 - val_sparse_categorical_accuracy: 0.9807\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0497 - sparse_categorical_accuracy: 0.9848 - val_loss: 0.0702 - val_sparse_categorical_accuracy: 0.9786\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0388 - sparse_categorical_accuracy: 0.9879 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9829\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0301 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.0914 - val_sparse_categorical_accuracy: 0.9723\n",
            "Epoch 6/100\n",
            "1969/1969 [==============================] - 117s 59ms/step - loss: 0.0230 - sparse_categorical_accuracy: 0.9930 - val_loss: 0.0626 - val_sparse_categorical_accuracy: 0.9830\n",
            "Epoch 00006: early stopping\n",
            "219/219 [==============================] - 4s 17ms/step - loss: 0.0626 - sparse_categorical_accuracy: 0.9830\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9829999804496765\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.0625789687037468\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9829583371990793\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 5\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 122s 62ms/step - loss: 0.3113 - sparse_categorical_accuracy: 0.9023 - val_loss: 0.1165 - val_sparse_categorical_accuracy: 0.9646\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 119s 61ms/step - loss: 0.0865 - sparse_categorical_accuracy: 0.9739 - val_loss: 0.0875 - val_sparse_categorical_accuracy: 0.9747\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0535 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.0903 - val_sparse_categorical_accuracy: 0.9726\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 119s 60ms/step - loss: 0.0374 - sparse_categorical_accuracy: 0.9881 - val_loss: 0.0741 - val_sparse_categorical_accuracy: 0.9806\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0309 - sparse_categorical_accuracy: 0.9904 - val_loss: 0.0523 - val_sparse_categorical_accuracy: 0.9863\n",
            "Epoch 6/100\n",
            "1969/1969 [==============================] - 119s 60ms/step - loss: 0.0232 - sparse_categorical_accuracy: 0.9927 - val_loss: 0.0632 - val_sparse_categorical_accuracy: 0.9814\n",
            "Epoch 7/100\n",
            "1969/1969 [==============================] - 121s 61ms/step - loss: 0.0190 - sparse_categorical_accuracy: 0.9939 - val_loss: 0.0396 - val_sparse_categorical_accuracy: 0.9893\n",
            "Epoch 8/100\n",
            "1969/1969 [==============================] - 119s 60ms/step - loss: 0.0165 - sparse_categorical_accuracy: 0.9947 - val_loss: 0.0370 - val_sparse_categorical_accuracy: 0.9909\n",
            "Epoch 9/100\n",
            "1969/1969 [==============================] - 119s 60ms/step - loss: 0.0152 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0402 - val_sparse_categorical_accuracy: 0.9890\n",
            "Epoch 10/100\n",
            "1969/1969 [==============================] - 119s 60ms/step - loss: 0.0113 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0452 - val_sparse_categorical_accuracy: 0.9880\n",
            "Epoch 00010: early stopping\n",
            "219/219 [==============================] - 4s 16ms/step - loss: 0.0452 - sparse_categorical_accuracy: 0.9880\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9879999756813049\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.045158255845308304\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9880513487572052\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 6\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 119s 61ms/step - loss: 0.3070 - sparse_categorical_accuracy: 0.9040 - val_loss: 0.1102 - val_sparse_categorical_accuracy: 0.9679\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0812 - sparse_categorical_accuracy: 0.9751 - val_loss: 0.0953 - val_sparse_categorical_accuracy: 0.9696\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 119s 61ms/step - loss: 0.0534 - sparse_categorical_accuracy: 0.9836 - val_loss: 0.0580 - val_sparse_categorical_accuracy: 0.9847\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 119s 61ms/step - loss: 0.0370 - sparse_categorical_accuracy: 0.9887 - val_loss: 0.0715 - val_sparse_categorical_accuracy: 0.9819\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 117s 59ms/step - loss: 0.0295 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.1135 - val_sparse_categorical_accuracy: 0.9656\n",
            "Epoch 00005: early stopping\n",
            "219/219 [==============================] - 4s 17ms/step - loss: 0.1135 - sparse_categorical_accuracy: 0.9656\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.965571403503418\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.1134663000702858\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9652565713303176\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 7\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 122s 62ms/step - loss: 0.2980 - sparse_categorical_accuracy: 0.9078 - val_loss: 0.1450 - val_sparse_categorical_accuracy: 0.9550\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 121s 62ms/step - loss: 0.0799 - sparse_categorical_accuracy: 0.9756 - val_loss: 0.1148 - val_sparse_categorical_accuracy: 0.9666\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0504 - sparse_categorical_accuracy: 0.9845 - val_loss: 0.0778 - val_sparse_categorical_accuracy: 0.9781\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 119s 61ms/step - loss: 0.0388 - sparse_categorical_accuracy: 0.9878 - val_loss: 0.0655 - val_sparse_categorical_accuracy: 0.9804\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0286 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.0557 - val_sparse_categorical_accuracy: 0.9844\n",
            "Epoch 6/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0226 - sparse_categorical_accuracy: 0.9929 - val_loss: 0.0600 - val_sparse_categorical_accuracy: 0.9836\n",
            "Epoch 7/100\n",
            "1969/1969 [==============================] - 119s 60ms/step - loss: 0.0193 - sparse_categorical_accuracy: 0.9938 - val_loss: 0.0476 - val_sparse_categorical_accuracy: 0.9861\n",
            "Epoch 8/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0165 - sparse_categorical_accuracy: 0.9947 - val_loss: 0.0468 - val_sparse_categorical_accuracy: 0.9884\n",
            "Epoch 9/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0138 - sparse_categorical_accuracy: 0.9953 - val_loss: 0.0508 - val_sparse_categorical_accuracy: 0.9867\n",
            "Epoch 10/100\n",
            "1969/1969 [==============================] - 119s 60ms/step - loss: 0.0136 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0364 - val_sparse_categorical_accuracy: 0.9901\n",
            "Epoch 11/100\n",
            "1969/1969 [==============================] - 119s 60ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0486 - val_sparse_categorical_accuracy: 0.9880\n",
            "Epoch 12/100\n",
            "1969/1969 [==============================] - 117s 60ms/step - loss: 0.0110 - sparse_categorical_accuracy: 0.9963 - val_loss: 0.0358 - val_sparse_categorical_accuracy: 0.9913\n",
            "Epoch 13/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0376 - val_sparse_categorical_accuracy: 0.9911\n",
            "Epoch 14/100\n",
            "1969/1969 [==============================] - 117s 59ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0354 - val_sparse_categorical_accuracy: 0.9923\n",
            "Epoch 15/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0369 - val_sparse_categorical_accuracy: 0.9917\n",
            "Epoch 16/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0406 - val_sparse_categorical_accuracy: 0.9907\n",
            "Epoch 00016: early stopping\n",
            "219/219 [==============================] - 4s 17ms/step - loss: 0.0406 - sparse_categorical_accuracy: 0.9907\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9907143115997314\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.04058290645480156\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9907418324761752\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 8\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 122s 62ms/step - loss: 0.3026 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.1385 - val_sparse_categorical_accuracy: 0.9580\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 119s 61ms/step - loss: 0.0819 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.0723 - val_sparse_categorical_accuracy: 0.9770\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0524 - sparse_categorical_accuracy: 0.9836 - val_loss: 0.0833 - val_sparse_categorical_accuracy: 0.9749\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0384 - sparse_categorical_accuracy: 0.9876 - val_loss: 0.0610 - val_sparse_categorical_accuracy: 0.9817\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 119s 60ms/step - loss: 0.0304 - sparse_categorical_accuracy: 0.9905 - val_loss: 0.0528 - val_sparse_categorical_accuracy: 0.9836\n",
            "Epoch 6/100\n",
            "1969/1969 [==============================] - 119s 60ms/step - loss: 0.0227 - sparse_categorical_accuracy: 0.9929 - val_loss: 0.0520 - val_sparse_categorical_accuracy: 0.9856\n",
            "Epoch 7/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0202 - sparse_categorical_accuracy: 0.9934 - val_loss: 0.0450 - val_sparse_categorical_accuracy: 0.9864\n",
            "Epoch 8/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0159 - sparse_categorical_accuracy: 0.9950 - val_loss: 0.0543 - val_sparse_categorical_accuracy: 0.9854\n",
            "Epoch 9/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0143 - sparse_categorical_accuracy: 0.9956 - val_loss: 0.0450 - val_sparse_categorical_accuracy: 0.9880\n",
            "Epoch 10/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0125 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.0505 - val_sparse_categorical_accuracy: 0.9857\n",
            "Epoch 11/100\n",
            "1969/1969 [==============================] - 119s 60ms/step - loss: 0.0113 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0404 - val_sparse_categorical_accuracy: 0.9873\n",
            "Epoch 12/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0101 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.0398 - val_sparse_categorical_accuracy: 0.9881\n",
            "Epoch 13/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0366 - val_sparse_categorical_accuracy: 0.9904\n",
            "Epoch 14/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0637 - val_sparse_categorical_accuracy: 0.9843\n",
            "Epoch 15/100\n",
            "1969/1969 [==============================] - 117s 60ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0369 - val_sparse_categorical_accuracy: 0.9901\n",
            "Epoch 00015: early stopping\n",
            "219/219 [==============================] - 4s 17ms/step - loss: 0.0369 - sparse_categorical_accuracy: 0.9901\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9901428818702698\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.03689217194914818\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9903041465078672\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 9\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 123s 62ms/step - loss: 0.3083 - sparse_categorical_accuracy: 0.9032 - val_loss: 0.0948 - val_sparse_categorical_accuracy: 0.9739\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0798 - sparse_categorical_accuracy: 0.9756 - val_loss: 0.0706 - val_sparse_categorical_accuracy: 0.9799\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0540 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.0786 - val_sparse_categorical_accuracy: 0.9766\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 119s 61ms/step - loss: 0.0393 - sparse_categorical_accuracy: 0.9880 - val_loss: 0.0545 - val_sparse_categorical_accuracy: 0.9826\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 119s 61ms/step - loss: 0.0296 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.0621 - val_sparse_categorical_accuracy: 0.9830\n",
            "Epoch 6/100\n",
            "1969/1969 [==============================] - 119s 61ms/step - loss: 0.0224 - sparse_categorical_accuracy: 0.9927 - val_loss: 0.0584 - val_sparse_categorical_accuracy: 0.9820\n",
            "Epoch 00006: early stopping\n",
            "219/219 [==============================] - 4s 17ms/step - loss: 0.0584 - sparse_categorical_accuracy: 0.9820\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9819999933242798\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.058395083993673325\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9818975540292174\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 10\n",
            "\n",
            "Epoch 1/100\n",
            "1969/1969 [==============================] - 121s 61ms/step - loss: 0.3079 - sparse_categorical_accuracy: 0.9043 - val_loss: 0.1325 - val_sparse_categorical_accuracy: 0.9591\n",
            "Epoch 2/100\n",
            "1969/1969 [==============================] - 119s 61ms/step - loss: 0.0829 - sparse_categorical_accuracy: 0.9746 - val_loss: 0.1002 - val_sparse_categorical_accuracy: 0.9696\n",
            "Epoch 3/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0527 - sparse_categorical_accuracy: 0.9842 - val_loss: 0.0817 - val_sparse_categorical_accuracy: 0.9747\n",
            "Epoch 4/100\n",
            "1969/1969 [==============================] - 119s 60ms/step - loss: 0.0383 - sparse_categorical_accuracy: 0.9883 - val_loss: 0.0760 - val_sparse_categorical_accuracy: 0.9763\n",
            "Epoch 5/100\n",
            "1969/1969 [==============================] - 121s 62ms/step - loss: 0.0298 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.0474 - val_sparse_categorical_accuracy: 0.9867\n",
            "Epoch 6/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0239 - sparse_categorical_accuracy: 0.9927 - val_loss: 0.0443 - val_sparse_categorical_accuracy: 0.9844\n",
            "Epoch 7/100\n",
            "1969/1969 [==============================] - 119s 61ms/step - loss: 0.0174 - sparse_categorical_accuracy: 0.9944 - val_loss: 0.0689 - val_sparse_categorical_accuracy: 0.9804\n",
            "Epoch 8/100\n",
            "1969/1969 [==============================] - 120s 61ms/step - loss: 0.0167 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.0379 - val_sparse_categorical_accuracy: 0.9874\n",
            "Epoch 9/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0137 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.0358 - val_sparse_categorical_accuracy: 0.9904\n",
            "Epoch 10/100\n",
            "1969/1969 [==============================] - 119s 61ms/step - loss: 0.0149 - sparse_categorical_accuracy: 0.9954 - val_loss: 0.0329 - val_sparse_categorical_accuracy: 0.9893\n",
            "Epoch 11/100\n",
            "1969/1969 [==============================] - 118s 60ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.0619 - val_sparse_categorical_accuracy: 0.9821\n",
            "Epoch 12/100\n",
            "1969/1969 [==============================] - 119s 60ms/step - loss: 0.0111 - sparse_categorical_accuracy: 0.9963 - val_loss: 0.0724 - val_sparse_categorical_accuracy: 0.9839\n",
            "Epoch 00012: early stopping\n",
            "219/219 [==============================] - 4s 16ms/step - loss: 0.0724 - sparse_categorical_accuracy: 0.9839\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9838571548461914\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.07237761467695236\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9839317492684329\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbdI7yFAb3XQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "b515e899-17a8-45e2-d831-65b01fd31b82"
      },
      "source": [
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(balancedAccuracies)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {losses[i]} - class-wise Accuracy: {balancedAccuracies[i]}% Accuracy - {baseAccuracies[i]} - Precision: {precisions[i]} - Recall: {recalls[i]} - F1: {f1scores[i]}')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(balancedAccuracies)} (+- {np.std(balancedAccuracies)})')\n",
        "print(f'> Loss: {np.mean(losses)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.05796632543206215 - class-wise Accuracy: 0.983936195240951% Accuracy - 0.984000027179718 - Precision: 0.9843008758558789 - Recall: 0.984 - F1: 0.9839708750449281\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.04799214377999306 - class-wise Accuracy: 0.9867653861921145% Accuracy - 0.9869999885559082 - Precision: 0.9872267120418164 - Recall: 0.987 - F1: 0.9870032070889638\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.04888124763965607 - class-wise Accuracy: 0.9872888000876913% Accuracy - 0.9874285459518433 - Precision: 0.9876182583992399 - Recall: 0.9874285714285714 - F1: 0.9874406293365656\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.0625789687037468 - class-wise Accuracy: 0.9829583371990793% Accuracy - 0.9829999804496765 - Precision: 0.9830788538898285 - Recall: 0.983 - F1: 0.9830123605830421\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.045158255845308304 - class-wise Accuracy: 0.9880513487572052% Accuracy - 0.9879999756813049 - Precision: 0.9880953761069268 - Recall: 0.988 - F1: 0.9880048664136449\n",
            "------------------------------------------------------------------------\n",
            "> Fold 6 - Loss: 0.1134663000702858 - class-wise Accuracy: 0.9652565713303176% Accuracy - 0.965571403503418 - Precision: 0.9677841884085366 - Recall: 0.9655714285714285 - F1: 0.9657027986867929\n",
            "------------------------------------------------------------------------\n",
            "> Fold 7 - Loss: 0.04058290645480156 - class-wise Accuracy: 0.9907418324761752% Accuracy - 0.9907143115997314 - Precision: 0.9907261822246797 - Recall: 0.9907142857142858 - F1: 0.9907112786219382\n",
            "------------------------------------------------------------------------\n",
            "> Fold 8 - Loss: 0.03689217194914818 - class-wise Accuracy: 0.9903041465078672% Accuracy - 0.9901428818702698 - Precision: 0.9902596808591297 - Recall: 0.9901428571428571 - F1: 0.9901649228910059\n",
            "------------------------------------------------------------------------\n",
            "> Fold 9 - Loss: 0.058395083993673325 - class-wise Accuracy: 0.9818975540292174% Accuracy - 0.9819999933242798 - Precision: 0.9823001657853283 - Recall: 0.982 - F1: 0.9820292050198133\n",
            "------------------------------------------------------------------------\n",
            "> Fold 10 - Loss: 0.07237761467695236 - class-wise Accuracy: 0.9839317492684329% Accuracy - 0.9838571548461914 - Precision: 0.9843756198404714 - Recall: 0.9838571428571429 - F1: 0.9838318112490144\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.9841131921089051 (+- 0.006904879617423578)\n",
            "> Loss: 0.05842910185456276\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp1zgELQcG7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}