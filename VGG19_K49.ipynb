{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG19_K49.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1-Ut3MQesdU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "9d49bd42-3bff-4524-efbf-0dfb97eb5993"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import svm, metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "from skimage.transform import resize, rescale\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import data, color\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from numpy import savez_compressed\n",
        "from google.colab import files\n",
        "from numpy import load\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.callbacks import EarlyStopping\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "filename = '/content/gdrive/My Drive/Research2/np_data/x.npz'\n",
        "x = np.load(filename)['arr_0']\n",
        "\n",
        "filename = '/content/gdrive/My Drive/Research2/np_data/y.npz'\n",
        "y = np.load(filename)['arr_0']\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "(270912, 56, 56, 1)\n",
            "(270912, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l54buI9Qe3XU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6046
        },
        "outputId": "a9ea8b34-a0dd-4287-cb9b-0c77d7cf8d36"
      },
      "source": [
        "baseAccuracies = []\n",
        "losses = []\n",
        "balancedAccuracies = []\n",
        "f1scores = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "fold_no = 1\n",
        "callback = EarlyStopping(monitor = 'val_loss', patience = 2, verbose = 1)\n",
        "\n",
        "for train, test in kfold.split(x, y):\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  print(\"Fold number: \" + str(fold_no))\n",
        "  fold_no = fold_no+1\n",
        "  print()\n",
        "\n",
        "  xtrain = x[train]\n",
        "  xtest = x[test]\n",
        "  \n",
        "  model = tf.keras.applications.VGG19(include_top=True, weights=None, input_shape=(56, 56, 1), classes=49, classifier_activation=\"softmax\",)\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=Adam(lr=0.0001), metrics=[\"sparse_categorical_accuracy\"])\n",
        "  model.fit(xtrain, y[train], verbose = 1, validation_data = (xtest, y[test]), epochs = 10, callbacks = [callback], batch_size = 32)\n",
        "\n",
        "  test_loss, test_accuracy = model.evaluate(xtest, y[test])\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  print(\"Test Accuracy:\")\n",
        "  print(test_accuracy)\n",
        "  baseAccuracies.append(test_accuracy)\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  print(\"Test Loss:\")\n",
        "  print(test_loss)\n",
        "  losses.append(test_loss)\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  preds = np.argmax(model.predict(xtest), axis=-1)\n",
        "  preds = preds.reshape(len(xtest), 1)\n",
        "  accs = []\n",
        "  for cls in range(49):\n",
        "    mask = (y[test] == cls)\n",
        "    cls_acc = (preds == cls)[mask].mean() \n",
        "    accs.append(cls_acc)\n",
        "  accs = np.mean(accs)\n",
        "  print(\"Final balanced accuracy:\")\n",
        "  print(accs)\n",
        "  balancedAccuracies.append(accs)\n",
        "  print(\"_________________________________________________________________________________________________________________________________\")\n",
        "  f1scores.append(f1_score(y[test], preds, average = 'weighted'))\n",
        "  precisions.append(precision_score(y[test], preds, average = 'weighted'))\n",
        "  recalls.append(recall_score(y[test], preds, average = 'weighted'))\n",
        "  print(\"*********************************************************************************************************************************\")\n",
        "  print()\n",
        "  print()\n",
        "  del model, xtrain, xtest"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 1\n",
            "\n",
            "Epoch 1/10\n",
            "   1/7620 [..............................] - ETA: 0s - loss: 3.8918 - sparse_categorical_accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0131s vs `on_train_batch_end` time: 0.0203s). Check your callbacks.\n",
            "7620/7620 [==============================] - 261s 34ms/step - loss: 0.7425 - sparse_categorical_accuracy: 0.7972 - val_loss: 0.2193 - val_sparse_categorical_accuracy: 0.9413\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.1717 - sparse_categorical_accuracy: 0.9546 - val_loss: 0.2084 - val_sparse_categorical_accuracy: 0.9457\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 261s 34ms/step - loss: 0.1183 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.1231 - val_sparse_categorical_accuracy: 0.9691\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 261s 34ms/step - loss: 0.0924 - sparse_categorical_accuracy: 0.9753 - val_loss: 0.1164 - val_sparse_categorical_accuracy: 0.9710\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.0743 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.1098 - val_sparse_categorical_accuracy: 0.9734\n",
            "Epoch 6/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.0636 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1115 - val_sparse_categorical_accuracy: 0.9731\n",
            "Epoch 7/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.0543 - sparse_categorical_accuracy: 0.9857 - val_loss: 0.1109 - val_sparse_categorical_accuracy: 0.9749\n",
            "Epoch 00007: early stopping\n",
            "847/847 [==============================] - 9s 11ms/step - loss: 0.1109 - sparse_categorical_accuracy: 0.9749\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9748634099960327\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.11087110638618469\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.970150469097529\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 2\n",
            "\n",
            "Epoch 1/10\n",
            "   1/7620 [..............................] - ETA: 0s - loss: 3.8918 - sparse_categorical_accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0128s vs `on_train_batch_end` time: 0.0201s). Check your callbacks.\n",
            "7620/7620 [==============================] - 263s 34ms/step - loss: 0.7707 - sparse_categorical_accuracy: 0.7897 - val_loss: 0.2228 - val_sparse_categorical_accuracy: 0.9411\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 262s 34ms/step - loss: 0.1768 - sparse_categorical_accuracy: 0.9539 - val_loss: 0.1397 - val_sparse_categorical_accuracy: 0.9648\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 261s 34ms/step - loss: 0.1199 - sparse_categorical_accuracy: 0.9687 - val_loss: 0.1294 - val_sparse_categorical_accuracy: 0.9687\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 261s 34ms/step - loss: 0.0923 - sparse_categorical_accuracy: 0.9760 - val_loss: 0.1317 - val_sparse_categorical_accuracy: 0.9693\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 261s 34ms/step - loss: 0.0765 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.1215 - val_sparse_categorical_accuracy: 0.9718\n",
            "Epoch 6/10\n",
            "7620/7620 [==============================] - 262s 34ms/step - loss: 0.0640 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.1072 - val_sparse_categorical_accuracy: 0.9748\n",
            "Epoch 7/10\n",
            "7620/7620 [==============================] - 261s 34ms/step - loss: 0.0552 - sparse_categorical_accuracy: 0.9854 - val_loss: 0.1099 - val_sparse_categorical_accuracy: 0.9760\n",
            "Epoch 8/10\n",
            "7620/7620 [==============================] - 262s 34ms/step - loss: 0.0492 - sparse_categorical_accuracy: 0.9868 - val_loss: 0.1151 - val_sparse_categorical_accuracy: 0.9744\n",
            "Epoch 00008: early stopping\n",
            "847/847 [==============================] - 9s 11ms/step - loss: 0.1151 - sparse_categorical_accuracy: 0.9744\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9743835926055908\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.1150965765118599\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9709517819699723\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 3\n",
            "\n",
            "Epoch 1/10\n",
            "   1/7620 [..............................] - ETA: 0s - loss: 3.8918 - sparse_categorical_accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0129s vs `on_train_batch_end` time: 0.0198s). Check your callbacks.\n",
            "7620/7620 [==============================] - 261s 34ms/step - loss: 0.7747 - sparse_categorical_accuracy: 0.7885 - val_loss: 0.2445 - val_sparse_categorical_accuracy: 0.9364\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.1740 - sparse_categorical_accuracy: 0.9549 - val_loss: 0.1626 - val_sparse_categorical_accuracy: 0.9601\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.1173 - sparse_categorical_accuracy: 0.9698 - val_loss: 0.1293 - val_sparse_categorical_accuracy: 0.9689\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.0902 - sparse_categorical_accuracy: 0.9766 - val_loss: 0.1294 - val_sparse_categorical_accuracy: 0.9717\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.0746 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.1361 - val_sparse_categorical_accuracy: 0.9703\n",
            "Epoch 00005: early stopping\n",
            "847/847 [==============================] - 9s 11ms/step - loss: 0.1361 - sparse_categorical_accuracy: 0.9703\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9702853560447693\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.13610680401325226\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9672033755654343\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 4\n",
            "\n",
            "Epoch 1/10\n",
            "   1/7620 [..............................] - ETA: 0s - loss: 3.8918 - sparse_categorical_accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0128s vs `on_train_batch_end` time: 0.0200s). Check your callbacks.\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.7440 - sparse_categorical_accuracy: 0.7978 - val_loss: 0.2055 - val_sparse_categorical_accuracy: 0.9461\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 259s 34ms/step - loss: 0.1682 - sparse_categorical_accuracy: 0.9555 - val_loss: 0.1596 - val_sparse_categorical_accuracy: 0.9581\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.1155 - sparse_categorical_accuracy: 0.9699 - val_loss: 0.1333 - val_sparse_categorical_accuracy: 0.9671\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.0903 - sparse_categorical_accuracy: 0.9761 - val_loss: 0.1255 - val_sparse_categorical_accuracy: 0.9700\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.0752 - sparse_categorical_accuracy: 0.9803 - val_loss: 0.1100 - val_sparse_categorical_accuracy: 0.9733\n",
            "Epoch 6/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.0624 - sparse_categorical_accuracy: 0.9835 - val_loss: 0.1142 - val_sparse_categorical_accuracy: 0.9726\n",
            "Epoch 7/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.0540 - sparse_categorical_accuracy: 0.9857 - val_loss: 0.1142 - val_sparse_categorical_accuracy: 0.9736\n",
            "Epoch 00007: early stopping\n",
            "847/847 [==============================] - 9s 11ms/step - loss: 0.1142 - sparse_categorical_accuracy: 0.9736\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9735705852508545\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.1141953319311142\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.969051016431333\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 5\n",
            "\n",
            "Epoch 1/10\n",
            "   1/7620 [..............................] - ETA: 0s - loss: 3.8918 - sparse_categorical_accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0127s vs `on_train_batch_end` time: 0.0202s). Check your callbacks.\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.7486 - sparse_categorical_accuracy: 0.7946 - val_loss: 0.2609 - val_sparse_categorical_accuracy: 0.9320\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.1709 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.1517 - val_sparse_categorical_accuracy: 0.9594\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.1171 - sparse_categorical_accuracy: 0.9696 - val_loss: 0.1337 - val_sparse_categorical_accuracy: 0.9660\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.0896 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.1251 - val_sparse_categorical_accuracy: 0.9695\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.0739 - sparse_categorical_accuracy: 0.9803 - val_loss: 0.1192 - val_sparse_categorical_accuracy: 0.9718\n",
            "Epoch 6/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.0624 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.1090 - val_sparse_categorical_accuracy: 0.9736\n",
            "Epoch 7/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.0538 - sparse_categorical_accuracy: 0.9855 - val_loss: 0.1214 - val_sparse_categorical_accuracy: 0.9731\n",
            "Epoch 8/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.0479 - sparse_categorical_accuracy: 0.9873 - val_loss: 0.1261 - val_sparse_categorical_accuracy: 0.9741\n",
            "Epoch 00008: early stopping\n",
            "847/847 [==============================] - 9s 11ms/step - loss: 0.1261 - sparse_categorical_accuracy: 0.9741\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9740504026412964\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.1260693371295929\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9685114962741656\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 6\n",
            "\n",
            "Epoch 1/10\n",
            "   1/7620 [..............................] - ETA: 0s - loss: 3.8918 - sparse_categorical_accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0137s vs `on_train_batch_end` time: 0.0215s). Check your callbacks.\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.8052 - sparse_categorical_accuracy: 0.7799 - val_loss: 0.2355 - val_sparse_categorical_accuracy: 0.9378\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.1786 - sparse_categorical_accuracy: 0.9535 - val_loss: 0.1435 - val_sparse_categorical_accuracy: 0.9628\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.1233 - sparse_categorical_accuracy: 0.9676 - val_loss: 0.1307 - val_sparse_categorical_accuracy: 0.9672\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.0946 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.1204 - val_sparse_categorical_accuracy: 0.9703\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 259s 34ms/step - loss: 0.0760 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1192 - val_sparse_categorical_accuracy: 0.9713\n",
            "Epoch 6/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.0640 - sparse_categorical_accuracy: 0.9827 - val_loss: 0.1257 - val_sparse_categorical_accuracy: 0.9721\n",
            "Epoch 7/10\n",
            "7620/7620 [==============================] - 260s 34ms/step - loss: 0.0555 - sparse_categorical_accuracy: 0.9850 - val_loss: 0.1122 - val_sparse_categorical_accuracy: 0.9756\n",
            "Epoch 8/10\n",
            "7620/7620 [==============================] - 261s 34ms/step - loss: 0.0485 - sparse_categorical_accuracy: 0.9866 - val_loss: 0.1163 - val_sparse_categorical_accuracy: 0.9750\n",
            "Epoch 9/10\n",
            "7620/7620 [==============================] - 262s 34ms/step - loss: 0.0429 - sparse_categorical_accuracy: 0.9881 - val_loss: 0.1292 - val_sparse_categorical_accuracy: 0.9750\n",
            "Epoch 00009: early stopping\n",
            "847/847 [==============================] - 9s 11ms/step - loss: 0.1292 - sparse_categorical_accuracy: 0.9750\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9749732613563538\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.1291569173336029\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9752616371277932\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 7\n",
            "\n",
            "Epoch 1/10\n",
            "   1/7620 [..............................] - ETA: 0s - loss: 3.8918 - sparse_categorical_accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0131s vs `on_train_batch_end` time: 0.0203s). Check your callbacks.\n",
            "7620/7620 [==============================] - 263s 35ms/step - loss: 0.7228 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.2343 - val_sparse_categorical_accuracy: 0.9363\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 264s 35ms/step - loss: 0.1848 - sparse_categorical_accuracy: 0.9508 - val_loss: 0.1652 - val_sparse_categorical_accuracy: 0.9550\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 264s 35ms/step - loss: 0.1251 - sparse_categorical_accuracy: 0.9668 - val_loss: 0.1378 - val_sparse_categorical_accuracy: 0.9652\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 263s 35ms/step - loss: 0.0963 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.1201 - val_sparse_categorical_accuracy: 0.9691\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 263s 35ms/step - loss: 0.0777 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.1340 - val_sparse_categorical_accuracy: 0.9659\n",
            "Epoch 6/10\n",
            "7620/7620 [==============================] - 263s 35ms/step - loss: 0.0652 - sparse_categorical_accuracy: 0.9823 - val_loss: 0.1239 - val_sparse_categorical_accuracy: 0.9699\n",
            "Epoch 00006: early stopping\n",
            "847/847 [==============================] - 9s 11ms/step - loss: 0.1239 - sparse_categorical_accuracy: 0.9699\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9699162244796753\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.12388011068105698\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9630067589765768\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 8\n",
            "\n",
            "Epoch 1/10\n",
            "7620/7620 [==============================] - 263s 35ms/step - loss: 0.8392 - sparse_categorical_accuracy: 0.7729 - val_loss: 0.2085 - val_sparse_categorical_accuracy: 0.9447\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 263s 35ms/step - loss: 0.1701 - sparse_categorical_accuracy: 0.9558 - val_loss: 0.1593 - val_sparse_categorical_accuracy: 0.9597\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 263s 34ms/step - loss: 0.1169 - sparse_categorical_accuracy: 0.9697 - val_loss: 0.1187 - val_sparse_categorical_accuracy: 0.9714\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 263s 34ms/step - loss: 0.0912 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.1089 - val_sparse_categorical_accuracy: 0.9743\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 262s 34ms/step - loss: 0.0734 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.1382 - val_sparse_categorical_accuracy: 0.9687\n",
            "Epoch 6/10\n",
            "7620/7620 [==============================] - 265s 35ms/step - loss: 0.0628 - sparse_categorical_accuracy: 0.9834 - val_loss: 0.1008 - val_sparse_categorical_accuracy: 0.9755\n",
            "Epoch 7/10\n",
            "7620/7620 [==============================] - 264s 35ms/step - loss: 0.0544 - sparse_categorical_accuracy: 0.9856 - val_loss: 0.1035 - val_sparse_categorical_accuracy: 0.9778\n",
            "Epoch 8/10\n",
            "7620/7620 [==============================] - 264s 35ms/step - loss: 0.0480 - sparse_categorical_accuracy: 0.9873 - val_loss: 0.1115 - val_sparse_categorical_accuracy: 0.9755\n",
            "Epoch 00008: early stopping\n",
            "847/847 [==============================] - 9s 11ms/step - loss: 0.1115 - sparse_categorical_accuracy: 0.9755\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9754530787467957\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.11146748811006546\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9708286061362584\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 9\n",
            "\n",
            "Epoch 1/10\n",
            "7620/7620 [==============================] - 264s 35ms/step - loss: 0.7578 - sparse_categorical_accuracy: 0.7937 - val_loss: 0.2372 - val_sparse_categorical_accuracy: 0.9357\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 263s 35ms/step - loss: 0.1746 - sparse_categorical_accuracy: 0.9536 - val_loss: 0.1533 - val_sparse_categorical_accuracy: 0.9616\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 262s 34ms/step - loss: 0.1209 - sparse_categorical_accuracy: 0.9684 - val_loss: 0.1418 - val_sparse_categorical_accuracy: 0.9637\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 263s 34ms/step - loss: 0.0937 - sparse_categorical_accuracy: 0.9753 - val_loss: 0.1165 - val_sparse_categorical_accuracy: 0.9704\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 263s 34ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9798 - val_loss: 0.1238 - val_sparse_categorical_accuracy: 0.9710\n",
            "Epoch 6/10\n",
            "7620/7620 [==============================] - 263s 34ms/step - loss: 0.0634 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.1140 - val_sparse_categorical_accuracy: 0.9721\n",
            "Epoch 7/10\n",
            "7620/7620 [==============================] - 262s 34ms/step - loss: 0.0566 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.1103 - val_sparse_categorical_accuracy: 0.9744\n",
            "Epoch 8/10\n",
            "7620/7620 [==============================] - 263s 35ms/step - loss: 0.0496 - sparse_categorical_accuracy: 0.9865 - val_loss: 0.1195 - val_sparse_categorical_accuracy: 0.9715\n",
            "Epoch 9/10\n",
            "7620/7620 [==============================] - 262s 34ms/step - loss: 0.0450 - sparse_categorical_accuracy: 0.9879 - val_loss: 0.1273 - val_sparse_categorical_accuracy: 0.9731\n",
            "Epoch 00009: early stopping\n",
            "847/847 [==============================] - 9s 11ms/step - loss: 0.1273 - sparse_categorical_accuracy: 0.9731\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9731276035308838\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.12729009985923767\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9697864136556289\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Fold number: 10\n",
            "\n",
            "Epoch 1/10\n",
            "   1/7620 [..............................] - ETA: 0s - loss: 3.8918 - sparse_categorical_accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0135s vs `on_train_batch_end` time: 0.0214s). Check your callbacks.\n",
            "7620/7620 [==============================] - 263s 34ms/step - loss: 0.7686 - sparse_categorical_accuracy: 0.7911 - val_loss: 0.2087 - val_sparse_categorical_accuracy: 0.9468\n",
            "Epoch 2/10\n",
            "7620/7620 [==============================] - 264s 35ms/step - loss: 0.1661 - sparse_categorical_accuracy: 0.9570 - val_loss: 0.1491 - val_sparse_categorical_accuracy: 0.9626\n",
            "Epoch 3/10\n",
            "7620/7620 [==============================] - 264s 35ms/step - loss: 0.1151 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.1291 - val_sparse_categorical_accuracy: 0.9678\n",
            "Epoch 4/10\n",
            "7620/7620 [==============================] - 264s 35ms/step - loss: 0.0883 - sparse_categorical_accuracy: 0.9768 - val_loss: 0.1165 - val_sparse_categorical_accuracy: 0.9729\n",
            "Epoch 5/10\n",
            "7620/7620 [==============================] - 263s 34ms/step - loss: 0.0730 - sparse_categorical_accuracy: 0.9807 - val_loss: 0.1162 - val_sparse_categorical_accuracy: 0.9734\n",
            "Epoch 6/10\n",
            "7620/7620 [==============================] - 263s 34ms/step - loss: 0.0622 - sparse_categorical_accuracy: 0.9839 - val_loss: 0.1130 - val_sparse_categorical_accuracy: 0.9760\n",
            "Epoch 7/10\n",
            "7620/7620 [==============================] - 263s 34ms/step - loss: 0.0535 - sparse_categorical_accuracy: 0.9860 - val_loss: 0.1463 - val_sparse_categorical_accuracy: 0.9715\n",
            "Epoch 8/10\n",
            "7620/7620 [==============================] - 263s 34ms/step - loss: 0.0478 - sparse_categorical_accuracy: 0.9873 - val_loss: 0.1243 - val_sparse_categorical_accuracy: 0.9750\n",
            "Epoch 00008: early stopping\n",
            "847/847 [==============================] - 9s 11ms/step - loss: 0.1243 - sparse_categorical_accuracy: 0.9750\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Accuracy:\n",
            "0.9749732613563538\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Test Loss:\n",
            "0.12434979528188705\n",
            "_________________________________________________________________________________________________________________________________\n",
            "Final balanced accuracy:\n",
            "0.9692440944703999\n",
            "_________________________________________________________________________________________________________________________________\n",
            "*********************************************************************************************************************************\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NCjwM3Je7kC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "9c06df3d-4096-4d0b-d1ea-a4038cc9aed0"
      },
      "source": [
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(balancedAccuracies)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {losses[i]} - class-wise Accuracy: {balancedAccuracies[i]}% Accuracy - {baseAccuracies[i]} - Precision: {precisions[i]} - Recall: {recalls[i]} - F1: {f1scores[i]}')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(balancedAccuracies)} (+- {np.std(balancedAccuracies)})')\n",
        "print(f'> Loss: {np.mean(losses)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.11087110638618469 - class-wise Accuracy: 0.970150469097529% Accuracy - 0.9748634099960327 - Precision: 0.9751247227611007 - Recall: 0.9748634283183227 - F1: 0.974899831887497\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.1150965765118599 - class-wise Accuracy: 0.9709517819699723% Accuracy - 0.9743835926055908 - Precision: 0.974633562725309 - Recall: 0.9743835818691865 - F1: 0.9743262407936553\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.13610680401325226 - class-wise Accuracy: 0.9672033755654343% Accuracy - 0.9702853560447693 - Precision: 0.9707067554506088 - Recall: 0.9702853346129711 - F1: 0.9703200663584816\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.1141953319311142 - class-wise Accuracy: 0.969051016431333% Accuracy - 0.9735705852508545 - Precision: 0.9738543741485439 - Recall: 0.9735705584880587 - F1: 0.9736016167049037\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.1260693371295929 - class-wise Accuracy: 0.9685114962741656% Accuracy - 0.9740504026412964 - Precision: 0.9742810213766168 - Recall: 0.9740504226495884 - F1: 0.974021267042479\n",
            "------------------------------------------------------------------------\n",
            "> Fold 6 - Loss: 0.1291569173336029 - class-wise Accuracy: 0.9752616371277932% Accuracy - 0.9749732613563538 - Precision: 0.9752055735492966 - Recall: 0.9749732383448377 - F1: 0.974994689837773\n",
            "------------------------------------------------------------------------\n",
            "> Fold 7 - Loss: 0.12388011068105698 - class-wise Accuracy: 0.9630067589765768% Accuracy - 0.9699162244796753 - Precision: 0.9701112287125682 - Recall: 0.9699162083348714 - F1: 0.9698562531014381\n",
            "------------------------------------------------------------------------\n",
            "> Fold 8 - Loss: 0.11146748811006546 - class-wise Accuracy: 0.9708286061362584% Accuracy - 0.9754530787467957 - Precision: 0.9756901501947035 - Recall: 0.9754531025063674 - F1: 0.9754322503915228\n",
            "------------------------------------------------------------------------\n",
            "> Fold 9 - Loss: 0.12729009985923767 - class-wise Accuracy: 0.9697864136556289% Accuracy - 0.9731276035308838 - Precision: 0.9732481262110145 - Recall: 0.9731276069543391 - F1: 0.9731226421141058\n",
            "------------------------------------------------------------------------\n",
            "> Fold 10 - Loss: 0.12434979528188705 - class-wise Accuracy: 0.9692440944703999% Accuracy - 0.9749732613563538 - Precision: 0.975143359158968 - Recall: 0.9749732383448377 - F1: 0.9749549141670095\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.9693995649705093 (+- 0.0029352082499577332)\n",
            "> Loss: 0.1218483567237854\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItwpnxjYfAHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}